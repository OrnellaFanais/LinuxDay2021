{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linux Day 2021 RL Acrobot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP1kj+uopLA+Z5JK04uFW3O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OrnellaFanais/LinuxDay2021/blob/main/Linux_Day_2021_RL_Acrobot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2Fiv8cQVlC1"
      },
      "source": [
        "# **Working with OpenAI Gym**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7RYTEeSyb3z",
        "outputId": "c931c316-66ca-4076-c0d1-2221a652de3c"
      },
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install -y xvfb ffmpeg freeglut3-dev\n",
        "!pip install 'imageio==2.4.0'\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install tf-agents[reverb]\n",
        "!pip install pyglet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 14.2 kB/88.7\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 14.2 kB/88.7\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 14.2 kB/88.7\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.142)\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [1 InRelease 43.1 kB/88.7 k\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r                                                                               \r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers]\r                                                                         \rHit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers]\r                                                                         \rHit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rHit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,431 kB]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,365 kB]\n",
            "Get:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,802 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,210 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,801 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [922 kB]\n",
            "Get:22 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [40.8 kB]\n",
            "Fetched 11.9 MB in 3s (3,899 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "freeglut3-dev is already the newest version (2.8.1-3).\n",
            "freeglut3-dev set to manually installed.\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 784 kB of archives.\n",
            "After this operation, 2,270 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.9 [784 kB]\n",
            "Fetched 784 kB in 1s (857 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 155047 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.9_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting imageio==2.4.0\n",
            "  Downloading imageio-2.4.0.tar.gz (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio==2.4.0) (1.19.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio==2.4.0) (7.1.2)\n",
            "Building wheels for collected packages: imageio\n",
            "  Building wheel for imageio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imageio: filename=imageio-2.4.0-py3-none-any.whl size=3303897 sha256=c31563f9d14c8bdb40ff893e1d3251361c68209b09c145c5cdfd2b61e8994e76\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/de/2f/6c5a75120d68a2c3138120c8d0ce1c6f9483a4b96307986bf2\n",
            "Successfully built imageio\n",
            "Installing collected packages: imageio\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed imageio-2.4.0\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-2.2-py3-none-any.whl (15 kB)\n",
            "Collecting EasyProcess\n",
            "  Downloading EasyProcess-0.3-py2.py3-none-any.whl (7.9 kB)\n",
            "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
            "Successfully installed EasyProcess-0.3 pyvirtualdisplay-2.2\n",
            "Collecting tf-agents[reverb]\n",
            "  Downloading tf_agents-0.10.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.19.5)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.3.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (7.1.2)\n",
            "Requirement already satisfied: tensorflow-probability>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (0.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.12.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.15.0)\n",
            "Requirement already satisfied: gym>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (0.17.3)\n",
            "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (3.7.4.3)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (0.12.0)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (0.4.0)\n",
            "Requirement already satisfied: tensorflow~=2.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (2.6.0)\n",
            "Collecting dm-reverb~=0.5.0\n",
            "  Downloading dm_reverb-0.5.0-cp37-cp37m-manylinux2010_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 31.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: portpicker in /usr/local/lib/python3.7/dist-packages (from dm-reverb~=0.5.0->tf-agents[reverb]) (1.3.9)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from dm-reverb~=0.5.0->tf-agents[reverb]) (0.1.6)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.0->tf-agents[reverb]) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.0->tf-agents[reverb]) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17.0->tf-agents[reverb]) (0.16.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6.0->tf-agents[reverb]) (0.4.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6.0->tf-agents[reverb]) (0.37.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6.0->tf-agents[reverb]) (2.6.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6.0->tf-agents[reverb]) (1.41.0)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6.0->tf-agents[reverb]) (5.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6.0->tf-agents[reverb]) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6.0->tf-agents[reverb]) (3.3.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6.0->tf-agents[reverb]) (3.1.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6.0->tf-agents[reverb]) (2.6.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6.0->tf-agents[reverb]) (1.6.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6.0->tf-agents[reverb]) (2.6.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6.0->tf-agents[reverb]) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6.0->tf-agents[reverb]) (1.12)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.6.0->tf-agents[reverb]) (1.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow~=2.6.0->tf-agents[reverb]) (1.5.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.6.0->tf-agents[reverb]) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.6.0->tf-agents[reverb]) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.6.0->tf-agents[reverb]) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.6.0->tf-agents[reverb]) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.6.0->tf-agents[reverb]) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.6.0->tf-agents[reverb]) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.6.0->tf-agents[reverb]) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.6.0->tf-agents[reverb]) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow~=2.6.0->tf-agents[reverb]) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow~=2.6.0->tf-agents[reverb]) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow~=2.6.0->tf-agents[reverb]) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow~=2.6.0->tf-agents[reverb]) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow~=2.6.0->tf-agents[reverb]) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow~=2.6.0->tf-agents[reverb]) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.6.0->tf-agents[reverb]) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.6.0->tf-agents[reverb]) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.6.0->tf-agents[reverb]) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.6.0->tf-agents[reverb]) (2021.5.30)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow~=2.6.0->tf-agents[reverb]) (3.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.13.0->tf-agents[reverb]) (4.4.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow~=2.6.0->tf-agents[reverb]) (3.6.0)\n",
            "Installing collected packages: tf-agents, dm-reverb\n",
            "Successfully installed dm-reverb-0.5.0 tf-agents-0.10.0\n",
            "Requirement already satisfied: pyglet in /usr/local/lib/python3.7/dist-packages (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hy0hpdNmE8y5"
      },
      "source": [
        "# Working with environments in OpenAI Gym"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTTEvAC9E307"
      },
      "source": [
        "import gym\n",
        "\n",
        "def features_env(env_name):\n",
        "  env = gym.make(env_name)\n",
        "  print(f\"Reward Range: {env.reward_range}\")\n",
        "  print(f\"Observation Space size: {env.observation_space}\")\n",
        "  print(f\"Action Space size: {env.action_space}\")\n",
        "  \n",
        "def features_env_spec(env_name):\n",
        "  spec = gym.spec(env_name)\n",
        "  print(f\"Max Episode Steps: {spec.max_episode_steps}\")  \n",
        "  print(f\"Nondeterministic: {spec.nondeterministic}\")\n",
        "  print(f\"Reward Threshold: {spec.reward_threshold}\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG3KZuFDK0Wp",
        "outputId": "a63732ae-d8bc-4c58-992a-68145b90c50d"
      },
      "source": [
        "env_name = 'Acrobot-v1' #@param [\"Acrobot-v1\", \"CartPole-v1\", \"MountainCar-v0\"]\n",
        "features_env(env_name)\n",
        "env = gym.make(env_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward Range: (-inf, inf)\n",
            "Observation Space size: Box(-28.274333953857422, 28.274333953857422, (6,), float32)\n",
            "Action Space size: Discrete(3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-VJ7PJpM3DM",
        "outputId": "9604f770-7544-4f8d-944a-fabdce7c813f"
      },
      "source": [
        "features_env_spec(env_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Episode Steps: 500\n",
            "Nondeterministic: False\n",
            "Reward Threshold: -100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8btAf3p2sbJ",
        "outputId": "87532ab0-ba1d-4950-f260-edd38b7331f8"
      },
      "source": [
        "env.reset()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.99987675, -0.01570013,  0.99984668,  0.01751027,  0.00964072,\n",
              "        0.08657703])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8XBUFckGzuW",
        "outputId": "4c496796-fc9f-4af7-ebe8-60063b65551c"
      },
      "source": [
        "env.step(action=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0.99999847,  0.001749  ,  0.99999471, -0.0032539 ,  0.16044516,\n",
              "        -0.28752225]), -1.0, False, {})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJbTCbXBG6mx",
        "outputId": "e9304de9-9517-4ca0-9185-614e533a8247"
      },
      "source": [
        "env.step(action=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0.99949227,  0.0318622 ,  0.99836357, -0.05718557,  0.13300569,\n",
              "        -0.23824422]), -1.0, False, {})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc_Ysm6426Ai",
        "outputId": "280ade82-cfaa-4f24-8c42-0b8e691baeaa"
      },
      "source": [
        "env.step(action=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0.99924366,  0.0388858 ,  0.99824385, -0.05923868, -0.06392295,\n",
              "         0.21855241]), -1.0, False, {})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYGKvidNGjBd",
        "outputId": "c0f257a2-5570-400b-cb73-ce794b0e3ce4"
      },
      "source": [
        "len(env.reset())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo2w_upl4hhg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7515021b-0324-48fa-f4b0-dc576b7c56d7"
      },
      "source": [
        "gym.envs.registry.all()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_values([EnvSpec(Copy-v0), EnvSpec(RepeatCopy-v0), EnvSpec(ReversedAddition-v0), EnvSpec(ReversedAddition3-v0), EnvSpec(DuplicatedInput-v0), EnvSpec(Reverse-v0), EnvSpec(CartPole-v0), EnvSpec(CartPole-v1), EnvSpec(MountainCar-v0), EnvSpec(MountainCarContinuous-v0), EnvSpec(Pendulum-v0), EnvSpec(Acrobot-v1), EnvSpec(LunarLander-v2), EnvSpec(LunarLanderContinuous-v2), EnvSpec(BipedalWalker-v3), EnvSpec(BipedalWalkerHardcore-v3), EnvSpec(CarRacing-v0), EnvSpec(Blackjack-v0), EnvSpec(KellyCoinflip-v0), EnvSpec(KellyCoinflipGeneralized-v0), EnvSpec(FrozenLake-v0), EnvSpec(FrozenLake8x8-v0), EnvSpec(CliffWalking-v0), EnvSpec(NChain-v0), EnvSpec(Roulette-v0), EnvSpec(Taxi-v3), EnvSpec(GuessingGame-v0), EnvSpec(HotterColder-v0), EnvSpec(Reacher-v2), EnvSpec(Pusher-v2), EnvSpec(Thrower-v2), EnvSpec(Striker-v2), EnvSpec(InvertedPendulum-v2), EnvSpec(InvertedDoublePendulum-v2), EnvSpec(HalfCheetah-v2), EnvSpec(HalfCheetah-v3), EnvSpec(Hopper-v2), EnvSpec(Hopper-v3), EnvSpec(Swimmer-v2), EnvSpec(Swimmer-v3), EnvSpec(Walker2d-v2), EnvSpec(Walker2d-v3), EnvSpec(Ant-v2), EnvSpec(Ant-v3), EnvSpec(Humanoid-v2), EnvSpec(Humanoid-v3), EnvSpec(HumanoidStandup-v2), EnvSpec(FetchSlide-v1), EnvSpec(FetchPickAndPlace-v1), EnvSpec(FetchReach-v1), EnvSpec(FetchPush-v1), EnvSpec(HandReach-v0), EnvSpec(HandManipulateBlockRotateZ-v0), EnvSpec(HandManipulateBlockRotateZTouchSensors-v0), EnvSpec(HandManipulateBlockRotateZTouchSensors-v1), EnvSpec(HandManipulateBlockRotateParallel-v0), EnvSpec(HandManipulateBlockRotateParallelTouchSensors-v0), EnvSpec(HandManipulateBlockRotateParallelTouchSensors-v1), EnvSpec(HandManipulateBlockRotateXYZ-v0), EnvSpec(HandManipulateBlockRotateXYZTouchSensors-v0), EnvSpec(HandManipulateBlockRotateXYZTouchSensors-v1), EnvSpec(HandManipulateBlockFull-v0), EnvSpec(HandManipulateBlock-v0), EnvSpec(HandManipulateBlockTouchSensors-v0), EnvSpec(HandManipulateBlockTouchSensors-v1), EnvSpec(HandManipulateEggRotate-v0), EnvSpec(HandManipulateEggRotateTouchSensors-v0), EnvSpec(HandManipulateEggRotateTouchSensors-v1), EnvSpec(HandManipulateEggFull-v0), EnvSpec(HandManipulateEgg-v0), EnvSpec(HandManipulateEggTouchSensors-v0), EnvSpec(HandManipulateEggTouchSensors-v1), EnvSpec(HandManipulatePenRotate-v0), EnvSpec(HandManipulatePenRotateTouchSensors-v0), EnvSpec(HandManipulatePenRotateTouchSensors-v1), EnvSpec(HandManipulatePenFull-v0), EnvSpec(HandManipulatePen-v0), EnvSpec(HandManipulatePenTouchSensors-v0), EnvSpec(HandManipulatePenTouchSensors-v1), EnvSpec(FetchSlideDense-v1), EnvSpec(FetchPickAndPlaceDense-v1), EnvSpec(FetchReachDense-v1), EnvSpec(FetchPushDense-v1), EnvSpec(HandReachDense-v0), EnvSpec(HandManipulateBlockRotateZDense-v0), EnvSpec(HandManipulateBlockRotateZTouchSensorsDense-v0), EnvSpec(HandManipulateBlockRotateZTouchSensorsDense-v1), EnvSpec(HandManipulateBlockRotateParallelDense-v0), EnvSpec(HandManipulateBlockRotateParallelTouchSensorsDense-v0), EnvSpec(HandManipulateBlockRotateParallelTouchSensorsDense-v1), EnvSpec(HandManipulateBlockRotateXYZDense-v0), EnvSpec(HandManipulateBlockRotateXYZTouchSensorsDense-v0), EnvSpec(HandManipulateBlockRotateXYZTouchSensorsDense-v1), EnvSpec(HandManipulateBlockFullDense-v0), EnvSpec(HandManipulateBlockDense-v0), EnvSpec(HandManipulateBlockTouchSensorsDense-v0), EnvSpec(HandManipulateBlockTouchSensorsDense-v1), EnvSpec(HandManipulateEggRotateDense-v0), EnvSpec(HandManipulateEggRotateTouchSensorsDense-v0), EnvSpec(HandManipulateEggRotateTouchSensorsDense-v1), EnvSpec(HandManipulateEggFullDense-v0), EnvSpec(HandManipulateEggDense-v0), EnvSpec(HandManipulateEggTouchSensorsDense-v0), EnvSpec(HandManipulateEggTouchSensorsDense-v1), EnvSpec(HandManipulatePenRotateDense-v0), EnvSpec(HandManipulatePenRotateTouchSensorsDense-v0), EnvSpec(HandManipulatePenRotateTouchSensorsDense-v1), EnvSpec(HandManipulatePenFullDense-v0), EnvSpec(HandManipulatePenDense-v0), EnvSpec(HandManipulatePenTouchSensorsDense-v0), EnvSpec(HandManipulatePenTouchSensorsDense-v1), EnvSpec(Adventure-v0), EnvSpec(Adventure-v4), EnvSpec(AdventureDeterministic-v0), EnvSpec(AdventureDeterministic-v4), EnvSpec(AdventureNoFrameskip-v0), EnvSpec(AdventureNoFrameskip-v4), EnvSpec(Adventure-ram-v0), EnvSpec(Adventure-ram-v4), EnvSpec(Adventure-ramDeterministic-v0), EnvSpec(Adventure-ramDeterministic-v4), EnvSpec(Adventure-ramNoFrameskip-v0), EnvSpec(Adventure-ramNoFrameskip-v4), EnvSpec(AirRaid-v0), EnvSpec(AirRaid-v4), EnvSpec(AirRaidDeterministic-v0), EnvSpec(AirRaidDeterministic-v4), EnvSpec(AirRaidNoFrameskip-v0), EnvSpec(AirRaidNoFrameskip-v4), EnvSpec(AirRaid-ram-v0), EnvSpec(AirRaid-ram-v4), EnvSpec(AirRaid-ramDeterministic-v0), EnvSpec(AirRaid-ramDeterministic-v4), EnvSpec(AirRaid-ramNoFrameskip-v0), EnvSpec(AirRaid-ramNoFrameskip-v4), EnvSpec(Alien-v0), EnvSpec(Alien-v4), EnvSpec(AlienDeterministic-v0), EnvSpec(AlienDeterministic-v4), EnvSpec(AlienNoFrameskip-v0), EnvSpec(AlienNoFrameskip-v4), EnvSpec(Alien-ram-v0), EnvSpec(Alien-ram-v4), EnvSpec(Alien-ramDeterministic-v0), EnvSpec(Alien-ramDeterministic-v4), EnvSpec(Alien-ramNoFrameskip-v0), EnvSpec(Alien-ramNoFrameskip-v4), EnvSpec(Amidar-v0), EnvSpec(Amidar-v4), EnvSpec(AmidarDeterministic-v0), EnvSpec(AmidarDeterministic-v4), EnvSpec(AmidarNoFrameskip-v0), EnvSpec(AmidarNoFrameskip-v4), EnvSpec(Amidar-ram-v0), EnvSpec(Amidar-ram-v4), EnvSpec(Amidar-ramDeterministic-v0), EnvSpec(Amidar-ramDeterministic-v4), EnvSpec(Amidar-ramNoFrameskip-v0), EnvSpec(Amidar-ramNoFrameskip-v4), EnvSpec(Assault-v0), EnvSpec(Assault-v4), EnvSpec(AssaultDeterministic-v0), EnvSpec(AssaultDeterministic-v4), EnvSpec(AssaultNoFrameskip-v0), EnvSpec(AssaultNoFrameskip-v4), EnvSpec(Assault-ram-v0), EnvSpec(Assault-ram-v4), EnvSpec(Assault-ramDeterministic-v0), EnvSpec(Assault-ramDeterministic-v4), EnvSpec(Assault-ramNoFrameskip-v0), EnvSpec(Assault-ramNoFrameskip-v4), EnvSpec(Asterix-v0), EnvSpec(Asterix-v4), EnvSpec(AsterixDeterministic-v0), EnvSpec(AsterixDeterministic-v4), EnvSpec(AsterixNoFrameskip-v0), EnvSpec(AsterixNoFrameskip-v4), EnvSpec(Asterix-ram-v0), EnvSpec(Asterix-ram-v4), EnvSpec(Asterix-ramDeterministic-v0), EnvSpec(Asterix-ramDeterministic-v4), EnvSpec(Asterix-ramNoFrameskip-v0), EnvSpec(Asterix-ramNoFrameskip-v4), EnvSpec(Asteroids-v0), EnvSpec(Asteroids-v4), EnvSpec(AsteroidsDeterministic-v0), EnvSpec(AsteroidsDeterministic-v4), EnvSpec(AsteroidsNoFrameskip-v0), EnvSpec(AsteroidsNoFrameskip-v4), EnvSpec(Asteroids-ram-v0), EnvSpec(Asteroids-ram-v4), EnvSpec(Asteroids-ramDeterministic-v0), EnvSpec(Asteroids-ramDeterministic-v4), EnvSpec(Asteroids-ramNoFrameskip-v0), EnvSpec(Asteroids-ramNoFrameskip-v4), EnvSpec(Atlantis-v0), EnvSpec(Atlantis-v4), EnvSpec(AtlantisDeterministic-v0), EnvSpec(AtlantisDeterministic-v4), EnvSpec(AtlantisNoFrameskip-v0), EnvSpec(AtlantisNoFrameskip-v4), EnvSpec(Atlantis-ram-v0), EnvSpec(Atlantis-ram-v4), EnvSpec(Atlantis-ramDeterministic-v0), EnvSpec(Atlantis-ramDeterministic-v4), EnvSpec(Atlantis-ramNoFrameskip-v0), EnvSpec(Atlantis-ramNoFrameskip-v4), EnvSpec(BankHeist-v0), EnvSpec(BankHeist-v4), EnvSpec(BankHeistDeterministic-v0), EnvSpec(BankHeistDeterministic-v4), EnvSpec(BankHeistNoFrameskip-v0), EnvSpec(BankHeistNoFrameskip-v4), EnvSpec(BankHeist-ram-v0), EnvSpec(BankHeist-ram-v4), EnvSpec(BankHeist-ramDeterministic-v0), EnvSpec(BankHeist-ramDeterministic-v4), EnvSpec(BankHeist-ramNoFrameskip-v0), EnvSpec(BankHeist-ramNoFrameskip-v4), EnvSpec(BattleZone-v0), EnvSpec(BattleZone-v4), EnvSpec(BattleZoneDeterministic-v0), EnvSpec(BattleZoneDeterministic-v4), EnvSpec(BattleZoneNoFrameskip-v0), EnvSpec(BattleZoneNoFrameskip-v4), EnvSpec(BattleZone-ram-v0), EnvSpec(BattleZone-ram-v4), EnvSpec(BattleZone-ramDeterministic-v0), EnvSpec(BattleZone-ramDeterministic-v4), EnvSpec(BattleZone-ramNoFrameskip-v0), EnvSpec(BattleZone-ramNoFrameskip-v4), EnvSpec(BeamRider-v0), EnvSpec(BeamRider-v4), EnvSpec(BeamRiderDeterministic-v0), EnvSpec(BeamRiderDeterministic-v4), EnvSpec(BeamRiderNoFrameskip-v0), EnvSpec(BeamRiderNoFrameskip-v4), EnvSpec(BeamRider-ram-v0), EnvSpec(BeamRider-ram-v4), EnvSpec(BeamRider-ramDeterministic-v0), EnvSpec(BeamRider-ramDeterministic-v4), EnvSpec(BeamRider-ramNoFrameskip-v0), EnvSpec(BeamRider-ramNoFrameskip-v4), EnvSpec(Berzerk-v0), EnvSpec(Berzerk-v4), EnvSpec(BerzerkDeterministic-v0), EnvSpec(BerzerkDeterministic-v4), EnvSpec(BerzerkNoFrameskip-v0), EnvSpec(BerzerkNoFrameskip-v4), EnvSpec(Berzerk-ram-v0), EnvSpec(Berzerk-ram-v4), EnvSpec(Berzerk-ramDeterministic-v0), EnvSpec(Berzerk-ramDeterministic-v4), EnvSpec(Berzerk-ramNoFrameskip-v0), EnvSpec(Berzerk-ramNoFrameskip-v4), EnvSpec(Bowling-v0), EnvSpec(Bowling-v4), EnvSpec(BowlingDeterministic-v0), EnvSpec(BowlingDeterministic-v4), EnvSpec(BowlingNoFrameskip-v0), EnvSpec(BowlingNoFrameskip-v4), EnvSpec(Bowling-ram-v0), EnvSpec(Bowling-ram-v4), EnvSpec(Bowling-ramDeterministic-v0), EnvSpec(Bowling-ramDeterministic-v4), EnvSpec(Bowling-ramNoFrameskip-v0), EnvSpec(Bowling-ramNoFrameskip-v4), EnvSpec(Boxing-v0), EnvSpec(Boxing-v4), EnvSpec(BoxingDeterministic-v0), EnvSpec(BoxingDeterministic-v4), EnvSpec(BoxingNoFrameskip-v0), EnvSpec(BoxingNoFrameskip-v4), EnvSpec(Boxing-ram-v0), EnvSpec(Boxing-ram-v4), EnvSpec(Boxing-ramDeterministic-v0), EnvSpec(Boxing-ramDeterministic-v4), EnvSpec(Boxing-ramNoFrameskip-v0), EnvSpec(Boxing-ramNoFrameskip-v4), EnvSpec(Breakout-v0), EnvSpec(Breakout-v4), EnvSpec(BreakoutDeterministic-v0), EnvSpec(BreakoutDeterministic-v4), EnvSpec(BreakoutNoFrameskip-v0), EnvSpec(BreakoutNoFrameskip-v4), EnvSpec(Breakout-ram-v0), EnvSpec(Breakout-ram-v4), EnvSpec(Breakout-ramDeterministic-v0), EnvSpec(Breakout-ramDeterministic-v4), EnvSpec(Breakout-ramNoFrameskip-v0), EnvSpec(Breakout-ramNoFrameskip-v4), EnvSpec(Carnival-v0), EnvSpec(Carnival-v4), EnvSpec(CarnivalDeterministic-v0), EnvSpec(CarnivalDeterministic-v4), EnvSpec(CarnivalNoFrameskip-v0), EnvSpec(CarnivalNoFrameskip-v4), EnvSpec(Carnival-ram-v0), EnvSpec(Carnival-ram-v4), EnvSpec(Carnival-ramDeterministic-v0), EnvSpec(Carnival-ramDeterministic-v4), EnvSpec(Carnival-ramNoFrameskip-v0), EnvSpec(Carnival-ramNoFrameskip-v4), EnvSpec(Centipede-v0), EnvSpec(Centipede-v4), EnvSpec(CentipedeDeterministic-v0), EnvSpec(CentipedeDeterministic-v4), EnvSpec(CentipedeNoFrameskip-v0), EnvSpec(CentipedeNoFrameskip-v4), EnvSpec(Centipede-ram-v0), EnvSpec(Centipede-ram-v4), EnvSpec(Centipede-ramDeterministic-v0), EnvSpec(Centipede-ramDeterministic-v4), EnvSpec(Centipede-ramNoFrameskip-v0), EnvSpec(Centipede-ramNoFrameskip-v4), EnvSpec(ChopperCommand-v0), EnvSpec(ChopperCommand-v4), EnvSpec(ChopperCommandDeterministic-v0), EnvSpec(ChopperCommandDeterministic-v4), EnvSpec(ChopperCommandNoFrameskip-v0), EnvSpec(ChopperCommandNoFrameskip-v4), EnvSpec(ChopperCommand-ram-v0), EnvSpec(ChopperCommand-ram-v4), EnvSpec(ChopperCommand-ramDeterministic-v0), EnvSpec(ChopperCommand-ramDeterministic-v4), EnvSpec(ChopperCommand-ramNoFrameskip-v0), EnvSpec(ChopperCommand-ramNoFrameskip-v4), EnvSpec(CrazyClimber-v0), EnvSpec(CrazyClimber-v4), EnvSpec(CrazyClimberDeterministic-v0), EnvSpec(CrazyClimberDeterministic-v4), EnvSpec(CrazyClimberNoFrameskip-v0), EnvSpec(CrazyClimberNoFrameskip-v4), EnvSpec(CrazyClimber-ram-v0), EnvSpec(CrazyClimber-ram-v4), EnvSpec(CrazyClimber-ramDeterministic-v0), EnvSpec(CrazyClimber-ramDeterministic-v4), EnvSpec(CrazyClimber-ramNoFrameskip-v0), EnvSpec(CrazyClimber-ramNoFrameskip-v4), EnvSpec(Defender-v0), EnvSpec(Defender-v4), EnvSpec(DefenderDeterministic-v0), EnvSpec(DefenderDeterministic-v4), EnvSpec(DefenderNoFrameskip-v0), EnvSpec(DefenderNoFrameskip-v4), EnvSpec(Defender-ram-v0), EnvSpec(Defender-ram-v4), EnvSpec(Defender-ramDeterministic-v0), EnvSpec(Defender-ramDeterministic-v4), EnvSpec(Defender-ramNoFrameskip-v0), EnvSpec(Defender-ramNoFrameskip-v4), EnvSpec(DemonAttack-v0), EnvSpec(DemonAttack-v4), EnvSpec(DemonAttackDeterministic-v0), EnvSpec(DemonAttackDeterministic-v4), EnvSpec(DemonAttackNoFrameskip-v0), EnvSpec(DemonAttackNoFrameskip-v4), EnvSpec(DemonAttack-ram-v0), EnvSpec(DemonAttack-ram-v4), EnvSpec(DemonAttack-ramDeterministic-v0), EnvSpec(DemonAttack-ramDeterministic-v4), EnvSpec(DemonAttack-ramNoFrameskip-v0), EnvSpec(DemonAttack-ramNoFrameskip-v4), EnvSpec(DoubleDunk-v0), EnvSpec(DoubleDunk-v4), EnvSpec(DoubleDunkDeterministic-v0), EnvSpec(DoubleDunkDeterministic-v4), EnvSpec(DoubleDunkNoFrameskip-v0), EnvSpec(DoubleDunkNoFrameskip-v4), EnvSpec(DoubleDunk-ram-v0), EnvSpec(DoubleDunk-ram-v4), EnvSpec(DoubleDunk-ramDeterministic-v0), EnvSpec(DoubleDunk-ramDeterministic-v4), EnvSpec(DoubleDunk-ramNoFrameskip-v0), EnvSpec(DoubleDunk-ramNoFrameskip-v4), EnvSpec(ElevatorAction-v0), EnvSpec(ElevatorAction-v4), EnvSpec(ElevatorActionDeterministic-v0), EnvSpec(ElevatorActionDeterministic-v4), EnvSpec(ElevatorActionNoFrameskip-v0), EnvSpec(ElevatorActionNoFrameskip-v4), EnvSpec(ElevatorAction-ram-v0), EnvSpec(ElevatorAction-ram-v4), EnvSpec(ElevatorAction-ramDeterministic-v0), EnvSpec(ElevatorAction-ramDeterministic-v4), EnvSpec(ElevatorAction-ramNoFrameskip-v0), EnvSpec(ElevatorAction-ramNoFrameskip-v4), EnvSpec(Enduro-v0), EnvSpec(Enduro-v4), EnvSpec(EnduroDeterministic-v0), EnvSpec(EnduroDeterministic-v4), EnvSpec(EnduroNoFrameskip-v0), EnvSpec(EnduroNoFrameskip-v4), EnvSpec(Enduro-ram-v0), EnvSpec(Enduro-ram-v4), EnvSpec(Enduro-ramDeterministic-v0), EnvSpec(Enduro-ramDeterministic-v4), EnvSpec(Enduro-ramNoFrameskip-v0), EnvSpec(Enduro-ramNoFrameskip-v4), EnvSpec(FishingDerby-v0), EnvSpec(FishingDerby-v4), EnvSpec(FishingDerbyDeterministic-v0), EnvSpec(FishingDerbyDeterministic-v4), EnvSpec(FishingDerbyNoFrameskip-v0), EnvSpec(FishingDerbyNoFrameskip-v4), EnvSpec(FishingDerby-ram-v0), EnvSpec(FishingDerby-ram-v4), EnvSpec(FishingDerby-ramDeterministic-v0), EnvSpec(FishingDerby-ramDeterministic-v4), EnvSpec(FishingDerby-ramNoFrameskip-v0), EnvSpec(FishingDerby-ramNoFrameskip-v4), EnvSpec(Freeway-v0), EnvSpec(Freeway-v4), EnvSpec(FreewayDeterministic-v0), EnvSpec(FreewayDeterministic-v4), EnvSpec(FreewayNoFrameskip-v0), EnvSpec(FreewayNoFrameskip-v4), EnvSpec(Freeway-ram-v0), EnvSpec(Freeway-ram-v4), EnvSpec(Freeway-ramDeterministic-v0), EnvSpec(Freeway-ramDeterministic-v4), EnvSpec(Freeway-ramNoFrameskip-v0), EnvSpec(Freeway-ramNoFrameskip-v4), EnvSpec(Frostbite-v0), EnvSpec(Frostbite-v4), EnvSpec(FrostbiteDeterministic-v0), EnvSpec(FrostbiteDeterministic-v4), EnvSpec(FrostbiteNoFrameskip-v0), EnvSpec(FrostbiteNoFrameskip-v4), EnvSpec(Frostbite-ram-v0), EnvSpec(Frostbite-ram-v4), EnvSpec(Frostbite-ramDeterministic-v0), EnvSpec(Frostbite-ramDeterministic-v4), EnvSpec(Frostbite-ramNoFrameskip-v0), EnvSpec(Frostbite-ramNoFrameskip-v4), EnvSpec(Gopher-v0), EnvSpec(Gopher-v4), EnvSpec(GopherDeterministic-v0), EnvSpec(GopherDeterministic-v4), EnvSpec(GopherNoFrameskip-v0), EnvSpec(GopherNoFrameskip-v4), EnvSpec(Gopher-ram-v0), EnvSpec(Gopher-ram-v4), EnvSpec(Gopher-ramDeterministic-v0), EnvSpec(Gopher-ramDeterministic-v4), EnvSpec(Gopher-ramNoFrameskip-v0), EnvSpec(Gopher-ramNoFrameskip-v4), EnvSpec(Gravitar-v0), EnvSpec(Gravitar-v4), EnvSpec(GravitarDeterministic-v0), EnvSpec(GravitarDeterministic-v4), EnvSpec(GravitarNoFrameskip-v0), EnvSpec(GravitarNoFrameskip-v4), EnvSpec(Gravitar-ram-v0), EnvSpec(Gravitar-ram-v4), EnvSpec(Gravitar-ramDeterministic-v0), EnvSpec(Gravitar-ramDeterministic-v4), EnvSpec(Gravitar-ramNoFrameskip-v0), EnvSpec(Gravitar-ramNoFrameskip-v4), EnvSpec(Hero-v0), EnvSpec(Hero-v4), EnvSpec(HeroDeterministic-v0), EnvSpec(HeroDeterministic-v4), EnvSpec(HeroNoFrameskip-v0), EnvSpec(HeroNoFrameskip-v4), EnvSpec(Hero-ram-v0), EnvSpec(Hero-ram-v4), EnvSpec(Hero-ramDeterministic-v0), EnvSpec(Hero-ramDeterministic-v4), EnvSpec(Hero-ramNoFrameskip-v0), EnvSpec(Hero-ramNoFrameskip-v4), EnvSpec(IceHockey-v0), EnvSpec(IceHockey-v4), EnvSpec(IceHockeyDeterministic-v0), EnvSpec(IceHockeyDeterministic-v4), EnvSpec(IceHockeyNoFrameskip-v0), EnvSpec(IceHockeyNoFrameskip-v4), EnvSpec(IceHockey-ram-v0), EnvSpec(IceHockey-ram-v4), EnvSpec(IceHockey-ramDeterministic-v0), EnvSpec(IceHockey-ramDeterministic-v4), EnvSpec(IceHockey-ramNoFrameskip-v0), EnvSpec(IceHockey-ramNoFrameskip-v4), EnvSpec(Jamesbond-v0), EnvSpec(Jamesbond-v4), EnvSpec(JamesbondDeterministic-v0), EnvSpec(JamesbondDeterministic-v4), EnvSpec(JamesbondNoFrameskip-v0), EnvSpec(JamesbondNoFrameskip-v4), EnvSpec(Jamesbond-ram-v0), EnvSpec(Jamesbond-ram-v4), EnvSpec(Jamesbond-ramDeterministic-v0), EnvSpec(Jamesbond-ramDeterministic-v4), EnvSpec(Jamesbond-ramNoFrameskip-v0), EnvSpec(Jamesbond-ramNoFrameskip-v4), EnvSpec(JourneyEscape-v0), EnvSpec(JourneyEscape-v4), EnvSpec(JourneyEscapeDeterministic-v0), EnvSpec(JourneyEscapeDeterministic-v4), EnvSpec(JourneyEscapeNoFrameskip-v0), EnvSpec(JourneyEscapeNoFrameskip-v4), EnvSpec(JourneyEscape-ram-v0), EnvSpec(JourneyEscape-ram-v4), EnvSpec(JourneyEscape-ramDeterministic-v0), EnvSpec(JourneyEscape-ramDeterministic-v4), EnvSpec(JourneyEscape-ramNoFrameskip-v0), EnvSpec(JourneyEscape-ramNoFrameskip-v4), EnvSpec(Kangaroo-v0), EnvSpec(Kangaroo-v4), EnvSpec(KangarooDeterministic-v0), EnvSpec(KangarooDeterministic-v4), EnvSpec(KangarooNoFrameskip-v0), EnvSpec(KangarooNoFrameskip-v4), EnvSpec(Kangaroo-ram-v0), EnvSpec(Kangaroo-ram-v4), EnvSpec(Kangaroo-ramDeterministic-v0), EnvSpec(Kangaroo-ramDeterministic-v4), EnvSpec(Kangaroo-ramNoFrameskip-v0), EnvSpec(Kangaroo-ramNoFrameskip-v4), EnvSpec(Krull-v0), EnvSpec(Krull-v4), EnvSpec(KrullDeterministic-v0), EnvSpec(KrullDeterministic-v4), EnvSpec(KrullNoFrameskip-v0), EnvSpec(KrullNoFrameskip-v4), EnvSpec(Krull-ram-v0), EnvSpec(Krull-ram-v4), EnvSpec(Krull-ramDeterministic-v0), EnvSpec(Krull-ramDeterministic-v4), EnvSpec(Krull-ramNoFrameskip-v0), EnvSpec(Krull-ramNoFrameskip-v4), EnvSpec(KungFuMaster-v0), EnvSpec(KungFuMaster-v4), EnvSpec(KungFuMasterDeterministic-v0), EnvSpec(KungFuMasterDeterministic-v4), EnvSpec(KungFuMasterNoFrameskip-v0), EnvSpec(KungFuMasterNoFrameskip-v4), EnvSpec(KungFuMaster-ram-v0), EnvSpec(KungFuMaster-ram-v4), EnvSpec(KungFuMaster-ramDeterministic-v0), EnvSpec(KungFuMaster-ramDeterministic-v4), EnvSpec(KungFuMaster-ramNoFrameskip-v0), EnvSpec(KungFuMaster-ramNoFrameskip-v4), EnvSpec(MontezumaRevenge-v0), EnvSpec(MontezumaRevenge-v4), EnvSpec(MontezumaRevengeDeterministic-v0), EnvSpec(MontezumaRevengeDeterministic-v4), EnvSpec(MontezumaRevengeNoFrameskip-v0), EnvSpec(MontezumaRevengeNoFrameskip-v4), EnvSpec(MontezumaRevenge-ram-v0), EnvSpec(MontezumaRevenge-ram-v4), EnvSpec(MontezumaRevenge-ramDeterministic-v0), EnvSpec(MontezumaRevenge-ramDeterministic-v4), EnvSpec(MontezumaRevenge-ramNoFrameskip-v0), EnvSpec(MontezumaRevenge-ramNoFrameskip-v4), EnvSpec(MsPacman-v0), EnvSpec(MsPacman-v4), EnvSpec(MsPacmanDeterministic-v0), EnvSpec(MsPacmanDeterministic-v4), EnvSpec(MsPacmanNoFrameskip-v0), EnvSpec(MsPacmanNoFrameskip-v4), EnvSpec(MsPacman-ram-v0), EnvSpec(MsPacman-ram-v4), EnvSpec(MsPacman-ramDeterministic-v0), EnvSpec(MsPacman-ramDeterministic-v4), EnvSpec(MsPacman-ramNoFrameskip-v0), EnvSpec(MsPacman-ramNoFrameskip-v4), EnvSpec(NameThisGame-v0), EnvSpec(NameThisGame-v4), EnvSpec(NameThisGameDeterministic-v0), EnvSpec(NameThisGameDeterministic-v4), EnvSpec(NameThisGameNoFrameskip-v0), EnvSpec(NameThisGameNoFrameskip-v4), EnvSpec(NameThisGame-ram-v0), EnvSpec(NameThisGame-ram-v4), EnvSpec(NameThisGame-ramDeterministic-v0), EnvSpec(NameThisGame-ramDeterministic-v4), EnvSpec(NameThisGame-ramNoFrameskip-v0), EnvSpec(NameThisGame-ramNoFrameskip-v4), EnvSpec(Phoenix-v0), EnvSpec(Phoenix-v4), EnvSpec(PhoenixDeterministic-v0), EnvSpec(PhoenixDeterministic-v4), EnvSpec(PhoenixNoFrameskip-v0), EnvSpec(PhoenixNoFrameskip-v4), EnvSpec(Phoenix-ram-v0), EnvSpec(Phoenix-ram-v4), EnvSpec(Phoenix-ramDeterministic-v0), EnvSpec(Phoenix-ramDeterministic-v4), EnvSpec(Phoenix-ramNoFrameskip-v0), EnvSpec(Phoenix-ramNoFrameskip-v4), EnvSpec(Pitfall-v0), EnvSpec(Pitfall-v4), EnvSpec(PitfallDeterministic-v0), EnvSpec(PitfallDeterministic-v4), EnvSpec(PitfallNoFrameskip-v0), EnvSpec(PitfallNoFrameskip-v4), EnvSpec(Pitfall-ram-v0), EnvSpec(Pitfall-ram-v4), EnvSpec(Pitfall-ramDeterministic-v0), EnvSpec(Pitfall-ramDeterministic-v4), EnvSpec(Pitfall-ramNoFrameskip-v0), EnvSpec(Pitfall-ramNoFrameskip-v4), EnvSpec(Pong-v0), EnvSpec(Pong-v4), EnvSpec(PongDeterministic-v0), EnvSpec(PongDeterministic-v4), EnvSpec(PongNoFrameskip-v0), EnvSpec(PongNoFrameskip-v4), EnvSpec(Pong-ram-v0), EnvSpec(Pong-ram-v4), EnvSpec(Pong-ramDeterministic-v0), EnvSpec(Pong-ramDeterministic-v4), EnvSpec(Pong-ramNoFrameskip-v0), EnvSpec(Pong-ramNoFrameskip-v4), EnvSpec(Pooyan-v0), EnvSpec(Pooyan-v4), EnvSpec(PooyanDeterministic-v0), EnvSpec(PooyanDeterministic-v4), EnvSpec(PooyanNoFrameskip-v0), EnvSpec(PooyanNoFrameskip-v4), EnvSpec(Pooyan-ram-v0), EnvSpec(Pooyan-ram-v4), EnvSpec(Pooyan-ramDeterministic-v0), EnvSpec(Pooyan-ramDeterministic-v4), EnvSpec(Pooyan-ramNoFrameskip-v0), EnvSpec(Pooyan-ramNoFrameskip-v4), EnvSpec(PrivateEye-v0), EnvSpec(PrivateEye-v4), EnvSpec(PrivateEyeDeterministic-v0), EnvSpec(PrivateEyeDeterministic-v4), EnvSpec(PrivateEyeNoFrameskip-v0), EnvSpec(PrivateEyeNoFrameskip-v4), EnvSpec(PrivateEye-ram-v0), EnvSpec(PrivateEye-ram-v4), EnvSpec(PrivateEye-ramDeterministic-v0), EnvSpec(PrivateEye-ramDeterministic-v4), EnvSpec(PrivateEye-ramNoFrameskip-v0), EnvSpec(PrivateEye-ramNoFrameskip-v4), EnvSpec(Qbert-v0), EnvSpec(Qbert-v4), EnvSpec(QbertDeterministic-v0), EnvSpec(QbertDeterministic-v4), EnvSpec(QbertNoFrameskip-v0), EnvSpec(QbertNoFrameskip-v4), EnvSpec(Qbert-ram-v0), EnvSpec(Qbert-ram-v4), EnvSpec(Qbert-ramDeterministic-v0), EnvSpec(Qbert-ramDeterministic-v4), EnvSpec(Qbert-ramNoFrameskip-v0), EnvSpec(Qbert-ramNoFrameskip-v4), EnvSpec(Riverraid-v0), EnvSpec(Riverraid-v4), EnvSpec(RiverraidDeterministic-v0), EnvSpec(RiverraidDeterministic-v4), EnvSpec(RiverraidNoFrameskip-v0), EnvSpec(RiverraidNoFrameskip-v4), EnvSpec(Riverraid-ram-v0), EnvSpec(Riverraid-ram-v4), EnvSpec(Riverraid-ramDeterministic-v0), EnvSpec(Riverraid-ramDeterministic-v4), EnvSpec(Riverraid-ramNoFrameskip-v0), EnvSpec(Riverraid-ramNoFrameskip-v4), EnvSpec(RoadRunner-v0), EnvSpec(RoadRunner-v4), EnvSpec(RoadRunnerDeterministic-v0), EnvSpec(RoadRunnerDeterministic-v4), EnvSpec(RoadRunnerNoFrameskip-v0), EnvSpec(RoadRunnerNoFrameskip-v4), EnvSpec(RoadRunner-ram-v0), EnvSpec(RoadRunner-ram-v4), EnvSpec(RoadRunner-ramDeterministic-v0), EnvSpec(RoadRunner-ramDeterministic-v4), EnvSpec(RoadRunner-ramNoFrameskip-v0), EnvSpec(RoadRunner-ramNoFrameskip-v4), EnvSpec(Robotank-v0), EnvSpec(Robotank-v4), EnvSpec(RobotankDeterministic-v0), EnvSpec(RobotankDeterministic-v4), EnvSpec(RobotankNoFrameskip-v0), EnvSpec(RobotankNoFrameskip-v4), EnvSpec(Robotank-ram-v0), EnvSpec(Robotank-ram-v4), EnvSpec(Robotank-ramDeterministic-v0), EnvSpec(Robotank-ramDeterministic-v4), EnvSpec(Robotank-ramNoFrameskip-v0), EnvSpec(Robotank-ramNoFrameskip-v4), EnvSpec(Seaquest-v0), EnvSpec(Seaquest-v4), EnvSpec(SeaquestDeterministic-v0), EnvSpec(SeaquestDeterministic-v4), EnvSpec(SeaquestNoFrameskip-v0), EnvSpec(SeaquestNoFrameskip-v4), EnvSpec(Seaquest-ram-v0), EnvSpec(Seaquest-ram-v4), EnvSpec(Seaquest-ramDeterministic-v0), EnvSpec(Seaquest-ramDeterministic-v4), EnvSpec(Seaquest-ramNoFrameskip-v0), EnvSpec(Seaquest-ramNoFrameskip-v4), EnvSpec(Skiing-v0), EnvSpec(Skiing-v4), EnvSpec(SkiingDeterministic-v0), EnvSpec(SkiingDeterministic-v4), EnvSpec(SkiingNoFrameskip-v0), EnvSpec(SkiingNoFrameskip-v4), EnvSpec(Skiing-ram-v0), EnvSpec(Skiing-ram-v4), EnvSpec(Skiing-ramDeterministic-v0), EnvSpec(Skiing-ramDeterministic-v4), EnvSpec(Skiing-ramNoFrameskip-v0), EnvSpec(Skiing-ramNoFrameskip-v4), EnvSpec(Solaris-v0), EnvSpec(Solaris-v4), EnvSpec(SolarisDeterministic-v0), EnvSpec(SolarisDeterministic-v4), EnvSpec(SolarisNoFrameskip-v0), EnvSpec(SolarisNoFrameskip-v4), EnvSpec(Solaris-ram-v0), EnvSpec(Solaris-ram-v4), EnvSpec(Solaris-ramDeterministic-v0), EnvSpec(Solaris-ramDeterministic-v4), EnvSpec(Solaris-ramNoFrameskip-v0), EnvSpec(Solaris-ramNoFrameskip-v4), EnvSpec(SpaceInvaders-v0), EnvSpec(SpaceInvaders-v4), EnvSpec(SpaceInvadersDeterministic-v0), EnvSpec(SpaceInvadersDeterministic-v4), EnvSpec(SpaceInvadersNoFrameskip-v0), EnvSpec(SpaceInvadersNoFrameskip-v4), EnvSpec(SpaceInvaders-ram-v0), EnvSpec(SpaceInvaders-ram-v4), EnvSpec(SpaceInvaders-ramDeterministic-v0), EnvSpec(SpaceInvaders-ramDeterministic-v4), EnvSpec(SpaceInvaders-ramNoFrameskip-v0), EnvSpec(SpaceInvaders-ramNoFrameskip-v4), EnvSpec(StarGunner-v0), EnvSpec(StarGunner-v4), EnvSpec(StarGunnerDeterministic-v0), EnvSpec(StarGunnerDeterministic-v4), EnvSpec(StarGunnerNoFrameskip-v0), EnvSpec(StarGunnerNoFrameskip-v4), EnvSpec(StarGunner-ram-v0), EnvSpec(StarGunner-ram-v4), EnvSpec(StarGunner-ramDeterministic-v0), EnvSpec(StarGunner-ramDeterministic-v4), EnvSpec(StarGunner-ramNoFrameskip-v0), EnvSpec(StarGunner-ramNoFrameskip-v4), EnvSpec(Tennis-v0), EnvSpec(Tennis-v4), EnvSpec(TennisDeterministic-v0), EnvSpec(TennisDeterministic-v4), EnvSpec(TennisNoFrameskip-v0), EnvSpec(TennisNoFrameskip-v4), EnvSpec(Tennis-ram-v0), EnvSpec(Tennis-ram-v4), EnvSpec(Tennis-ramDeterministic-v0), EnvSpec(Tennis-ramDeterministic-v4), EnvSpec(Tennis-ramNoFrameskip-v0), EnvSpec(Tennis-ramNoFrameskip-v4), EnvSpec(TimePilot-v0), EnvSpec(TimePilot-v4), EnvSpec(TimePilotDeterministic-v0), EnvSpec(TimePilotDeterministic-v4), EnvSpec(TimePilotNoFrameskip-v0), EnvSpec(TimePilotNoFrameskip-v4), EnvSpec(TimePilot-ram-v0), EnvSpec(TimePilot-ram-v4), EnvSpec(TimePilot-ramDeterministic-v0), EnvSpec(TimePilot-ramDeterministic-v4), EnvSpec(TimePilot-ramNoFrameskip-v0), EnvSpec(TimePilot-ramNoFrameskip-v4), EnvSpec(Tutankham-v0), EnvSpec(Tutankham-v4), EnvSpec(TutankhamDeterministic-v0), EnvSpec(TutankhamDeterministic-v4), EnvSpec(TutankhamNoFrameskip-v0), EnvSpec(TutankhamNoFrameskip-v4), EnvSpec(Tutankham-ram-v0), EnvSpec(Tutankham-ram-v4), EnvSpec(Tutankham-ramDeterministic-v0), EnvSpec(Tutankham-ramDeterministic-v4), EnvSpec(Tutankham-ramNoFrameskip-v0), EnvSpec(Tutankham-ramNoFrameskip-v4), EnvSpec(UpNDown-v0), EnvSpec(UpNDown-v4), EnvSpec(UpNDownDeterministic-v0), EnvSpec(UpNDownDeterministic-v4), EnvSpec(UpNDownNoFrameskip-v0), EnvSpec(UpNDownNoFrameskip-v4), EnvSpec(UpNDown-ram-v0), EnvSpec(UpNDown-ram-v4), EnvSpec(UpNDown-ramDeterministic-v0), EnvSpec(UpNDown-ramDeterministic-v4), EnvSpec(UpNDown-ramNoFrameskip-v0), EnvSpec(UpNDown-ramNoFrameskip-v4), EnvSpec(Venture-v0), EnvSpec(Venture-v4), EnvSpec(VentureDeterministic-v0), EnvSpec(VentureDeterministic-v4), EnvSpec(VentureNoFrameskip-v0), EnvSpec(VentureNoFrameskip-v4), EnvSpec(Venture-ram-v0), EnvSpec(Venture-ram-v4), EnvSpec(Venture-ramDeterministic-v0), EnvSpec(Venture-ramDeterministic-v4), EnvSpec(Venture-ramNoFrameskip-v0), EnvSpec(Venture-ramNoFrameskip-v4), EnvSpec(VideoPinball-v0), EnvSpec(VideoPinball-v4), EnvSpec(VideoPinballDeterministic-v0), EnvSpec(VideoPinballDeterministic-v4), EnvSpec(VideoPinballNoFrameskip-v0), EnvSpec(VideoPinballNoFrameskip-v4), EnvSpec(VideoPinball-ram-v0), EnvSpec(VideoPinball-ram-v4), EnvSpec(VideoPinball-ramDeterministic-v0), EnvSpec(VideoPinball-ramDeterministic-v4), EnvSpec(VideoPinball-ramNoFrameskip-v0), EnvSpec(VideoPinball-ramNoFrameskip-v4), EnvSpec(WizardOfWor-v0), EnvSpec(WizardOfWor-v4), EnvSpec(WizardOfWorDeterministic-v0), EnvSpec(WizardOfWorDeterministic-v4), EnvSpec(WizardOfWorNoFrameskip-v0), EnvSpec(WizardOfWorNoFrameskip-v4), EnvSpec(WizardOfWor-ram-v0), EnvSpec(WizardOfWor-ram-v4), EnvSpec(WizardOfWor-ramDeterministic-v0), EnvSpec(WizardOfWor-ramDeterministic-v4), EnvSpec(WizardOfWor-ramNoFrameskip-v0), EnvSpec(WizardOfWor-ramNoFrameskip-v4), EnvSpec(YarsRevenge-v0), EnvSpec(YarsRevenge-v4), EnvSpec(YarsRevengeDeterministic-v0), EnvSpec(YarsRevengeDeterministic-v4), EnvSpec(YarsRevengeNoFrameskip-v0), EnvSpec(YarsRevengeNoFrameskip-v4), EnvSpec(YarsRevenge-ram-v0), EnvSpec(YarsRevenge-ram-v4), EnvSpec(YarsRevenge-ramDeterministic-v0), EnvSpec(YarsRevenge-ramDeterministic-v4), EnvSpec(YarsRevenge-ramNoFrameskip-v0), EnvSpec(YarsRevenge-ramNoFrameskip-v4), EnvSpec(Zaxxon-v0), EnvSpec(Zaxxon-v4), EnvSpec(ZaxxonDeterministic-v0), EnvSpec(ZaxxonDeterministic-v4), EnvSpec(ZaxxonNoFrameskip-v0), EnvSpec(ZaxxonNoFrameskip-v4), EnvSpec(Zaxxon-ram-v0), EnvSpec(Zaxxon-ram-v4), EnvSpec(Zaxxon-ramDeterministic-v0), EnvSpec(Zaxxon-ramDeterministic-v4), EnvSpec(Zaxxon-ramNoFrameskip-v0), EnvSpec(Zaxxon-ramNoFrameskip-v4), EnvSpec(CubeCrash-v0), EnvSpec(CubeCrashSparse-v0), EnvSpec(CubeCrashScreenBecomesBlack-v0), EnvSpec(MemorizeDigits-v0)])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-8D7vZVTV0P",
        "outputId": "81fc8237-6ec8-45e8-cf4a-3a277d3b10d0"
      },
      "source": [
        "for episode in range(10): \n",
        "    obs = env.reset()\n",
        "    for step in range(50):\n",
        "        action = env.action_space.sample()  # or given a custom model, action = policy(observation)\n",
        "        nobs, reward, done, info = env.step(action)       \n",
        "        print(f\"Step {step}: State={nobs}, Reward={reward}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0: State=[ 0.99991019 -0.01340219  0.99354146  0.11346966 -0.19276511  0.27446038], Reward=-1.0\n",
            "Step 1: State=[ 0.99892783 -0.04629465  0.98838846  0.15194819 -0.12860646  0.10238494], Reward=-1.0\n",
            "Step 2: State=[ 0.99878776 -0.04922407  0.99310912  0.11719334  0.09865268 -0.4472668 ], Reward=-1.0\n",
            "Step 3: State=[ 0.99974199 -0.02271455  0.99988622  0.01508435  0.15794727 -0.55462366], Reward=-1.0\n",
            "Step 4: State=[ 0.99995124  0.0098751   0.99553265 -0.09441789  0.15789079 -0.51780377], Reward=-1.0\n",
            "Step 5: State=[ 0.99933359  0.03650161  0.98333931 -0.18177956  0.10055585 -0.34578773], Reward=-1.0\n",
            "Step 6: State=[ 0.99815675  0.06068864  0.96616767 -0.25791478  0.13423354 -0.41773176], Reward=-1.0\n",
            "Step 7: State=[ 0.99814117  0.06094428  0.96240409 -0.27162174 -0.13157515  0.27696345], Reward=-1.0\n",
            "Step 8: State=[ 0.99971711  0.02378465  0.98221195 -0.18777565 -0.2304531   0.56499287], Reward=-1.0\n",
            "Step 9: State=[ 0.99965937 -0.02609892  0.99822584 -0.05954136 -0.25432698  0.69830599], Reward=-1.0\n",
            "Step 10: State=[ 0.99828028 -0.05862156  0.99907318  0.04304398 -0.06160304  0.30566566], Reward=-1.0\n",
            "Step 11: State=[ 0.99880415 -0.04889032  0.99834356  0.05753376  0.15718847 -0.16096777], Reward=-1.0\n",
            "Step 12: State=[ 0.99999918  0.00127784  0.99985178 -0.01721653  0.33194875 -0.56575736], Reward=-1.0\n",
            "Step 13: State=[ 0.99704216  0.07685658  0.98777397 -0.15589285  0.40456691 -0.79084331], Reward=-1.0\n",
            "Step 14: State=[ 0.99179782  0.12781664  0.96905219 -0.24685593  0.09568604 -0.11690866], Reward=-1.0\n",
            "Step 15: State=[ 0.99028099  0.13908115  0.96420036 -0.26517479  0.0152243  -0.06788376], Reward=-1.0\n",
            "Step 16: State=[ 0.99271533  0.1204835   0.97094943 -0.23928477 -0.19807802  0.32800506], Reward=-1.0\n",
            "Step 17: State=[ 0.99793965  0.06415957  0.98968167 -0.14328359 -0.35331139  0.62549721], Reward=-1.0\n",
            "Step 18: State=[ 1.00000000e+00  2.44327530e-05  9.99251424e-01 -3.86857947e-02\n",
            " -2.72206472e-01  3.97221952e-01], Reward=-1.0\n",
            "Step 19: State=[ 0.99784709 -0.06558348  0.99722602  0.07443297 -0.36726545  0.70451497], Reward=-1.0\n",
            "Step 20: State=[ 0.99036364 -0.1384914   0.97403177  0.22641137 -0.34595178  0.79618264], Reward=-1.0\n",
            "Step 21: State=[ 0.98324363 -0.18229635  0.94141471  0.33725116 -0.08661505  0.3361616 ], Reward=-1.0\n",
            "Step 22: State=[ 0.98531834 -0.17072718  0.93669799  0.35013837  0.20165445 -0.19867228], Reward=-1.0\n",
            "Step 23: State=[ 0.99436229 -0.10603606  0.96400618  0.26587983  0.4362502  -0.66391853], Reward=-1.0\n",
            "Step 24: State=[ 0.99997105  0.00760927  0.99741657  0.0718344   0.6734788  -1.25779987], Reward=-1.0\n",
            "Step 25: State=[ 0.99083561  0.13507327  0.98504281 -0.17230978  0.57128933 -1.12942186], Reward=-1.0\n",
            "Step 26: State=[ 0.97504367  0.22201315  0.93694236 -0.34948391  0.29063478 -0.66772732], Reward=-1.0\n",
            "Step 27: State=[ 0.97295652  0.23098833  0.92273531 -0.38543424 -0.20008919  0.28626962], Reward=-1.0\n",
            "Step 28: State=[ 0.98917715  0.14672618  0.96953946 -0.24493516 -0.63823191  1.16260654], Reward=-1.0\n",
            "Step 29: State=[ 0.99985719  0.01689987  0.99976995 -0.02144868 -0.63132252  1.03668964], Reward=-1.0\n",
            "Step 30: State=[ 0.99577357 -0.09184226  0.98965629  0.14345878 -0.43056452  0.57250296], Reward=-1.0\n",
            "Step 31: State=[ 0.98722112 -0.15935642  0.97402229  0.22645217 -0.23432392  0.24872369], Reward=-1.0\n",
            "Step 32: State=[ 0.98116757 -0.1931585   0.96344844  0.26789383 -0.10114671  0.16715398], Reward=-1.0\n",
            "Step 33: State=[ 0.98037587 -0.19713742  0.95771954  0.28770347  0.06181157  0.03533456], Reward=-1.0\n",
            "Step 34: State=[ 0.98958456 -0.1439528   0.9763597   0.2161521   0.46519335 -0.75544763], Reward=-1.0\n",
            "Step 35: State=[ 0.99885596 -0.04782013  0.99732384  0.07311059  0.47681332 -0.65139505], Reward=-1.0\n",
            "Step 36: State=[ 0.99875477  0.04988896  0.99810954 -0.06146009  0.47658794 -0.65661387], Reward=-1.0\n",
            "Step 37: State=[ 0.99113737  0.13284097  0.98488094 -0.17323258  0.33665343 -0.43798158], Reward=-1.0\n",
            "Step 38: State=[ 0.98644351  0.16410119  0.98151336 -0.19139362 -0.02689518  0.25989592], Reward=-1.0\n",
            "Step 39: State=[ 0.99240327  0.12302742  0.99728828 -0.07359401 -0.37613205  0.9028645 ], Reward=-1.0\n",
            "Step 40: State=[ 0.99878472  0.04928577  0.99656882  0.0827683  -0.34430397  0.62386222], Reward=-1.0\n",
            "Step 41: State=[ 0.99997447 -0.00714577  0.98677297  0.16210832 -0.20677014  0.15433054], Reward=-1.0\n",
            "Step 42: State=[ 0.99908532 -0.04276117  0.98490795  0.173079   -0.1420321  -0.05019975], Reward=-1.0\n",
            "Step 43: State=[ 0.99809782 -0.06165013  0.98999393  0.14110999 -0.04432635 -0.2707472 ], Reward=-1.0\n",
            "Step 44: State=[ 0.99728997 -0.07357116  0.99470231  0.10279747 -0.07395752 -0.11049352], Reward=-1.0\n",
            "Step 45: State=[ 0.99702733 -0.07704871  0.9979639   0.06378131  0.03845258 -0.27464299], Reward=-1.0\n",
            "Step 46: State=[ 0.99822661 -0.05952851  0.99999662 -0.00260107  0.13142862 -0.37529894], Reward=-1.0\n",
            "Step 47: State=[ 0.99961718 -0.02766756  0.99685051 -0.07930364  0.1786109  -0.3743569 ], Reward=-1.0\n",
            "Step 48: State=[ 0.99977536  0.02119481  0.98402027 -0.17805648  0.29675957 -0.59654404], Reward=-1.0\n",
            "Step 49: State=[ 0.99744385  0.07145466  0.96324442 -0.26862649  0.19394152 -0.31059073], Reward=-1.0\n",
            "Step 0: State=[ 0.99943092 -0.0337318   0.99657458  0.08269886  0.12268702 -0.03575805], Reward=-1.0\n",
            "Step 1: State=[ 0.99998921 -0.00464613  0.99788558  0.0649952   0.16172944 -0.13413467], Reward=-1.0\n",
            "Step 2: State=[ 0.99960945  0.02794551  0.99945394  0.0330428   0.15662415 -0.17523649], Reward=-1.0\n",
            "Step 3: State=[ 0.99913038  0.04169519  0.99943305  0.03366865 -0.02155242  0.18304549], Reward=-1.0\n",
            "Step 4: State=[ 0.99891333  0.04660641  0.99938906  0.03495     0.06958208 -0.16932744], Reward=-1.0\n",
            "Step 5: State=[ 0.99768915  0.06794384  0.99952324 -0.03087541  0.13762702 -0.47410709], Reward=-1.0\n",
            "Step 6: State=[ 0.99639514  0.08483355  0.99372937 -0.11181211  0.02596777 -0.3212709 ], Reward=-1.0\n",
            "Step 7: State=[ 0.99795711  0.06388749  0.99276029 -0.12011249 -0.23158574  0.23521796], Reward=-1.0\n",
            "Step 8: State=[ 0.99999427 -0.0033848   0.99971397 -0.02391602 -0.42477916  0.70236355], Reward=-1.0\n",
            "Step 9: State=[ 0.99750235 -0.07063326  0.99705388  0.07670443 -0.23183322  0.27740599], Reward=-1.0\n",
            "Step 10: State=[ 0.99451261 -0.10461676  0.9934577   0.11420069 -0.10148062  0.08802123], Reward=-1.0\n",
            "Step 11: State=[ 0.99402489 -0.10915369  0.99401402  0.10925256  0.05642293 -0.13731349], Reward=-1.0\n",
            "Step 12: State=[ 0.99651853 -0.08337154  0.99807506  0.06201747  0.19577898 -0.32453751], Reward=-1.0\n",
            "Step 13: State=[ 0.99938491 -0.03506847  0.99991018 -0.01340286  0.27591913 -0.40945975], Reward=-1.0\n",
            "Step 14: State=[ 0.9999676   0.00805033  0.99830593 -0.05818308  0.14544552 -0.02478039], Reward=-1.0\n",
            "Step 15: State=[ 0.99978804  0.02058838  0.99977848 -0.02104754 -0.02122226  0.39153595], Reward=-1.0\n",
            "Step 16: State=[ 9.99999606e-01  8.88171941e-04  9.95706499e-01  9.25665561e-02\n",
            " -1.67795533e-01  7.22495154e-01], Reward=-1.0\n",
            "Step 17: State=[ 0.99959032 -0.02862164  0.97558491  0.21962258 -0.11762442  0.53872943], Reward=-1.0\n",
            "Step 18: State=[ 0.9984323  -0.05597277  0.94497847  0.32713254 -0.14722682  0.5566577 ], Reward=-1.0\n",
            "Step 19: State=[ 0.99648843 -0.08373058  0.90691893  0.42130517 -0.12296331  0.43951219], Reward=-1.0\n",
            "Step 20: State=[ 0.99476479 -0.10219105  0.87653455  0.48133895 -0.05753016  0.22119787], Reward=-1.0\n",
            "Step 21: State=[ 0.99443228 -0.10537761  0.86775648  0.49698963  0.02628943 -0.04444483], Reward=-1.0\n",
            "Step 22: State=[ 0.99574055 -0.09219952  0.88458748  0.4663743   0.10276561 -0.29789227], Reward=-1.0\n",
            "Step 23: State=[ 0.9977836  -0.06654238  0.9188472   0.3946135   0.1476958  -0.48171105], Reward=-1.0\n",
            "Step 24: State=[ 0.9999436  -0.01062096  0.97296281  0.23096184  0.3975524  -1.21076976], Reward=-1.0\n",
            "Step 25: State=[ 0.99754374  0.07004627  0.9997164  -0.02381441  0.3842278  -1.29957052], Reward=-1.0\n",
            "Step 26: State=[ 0.99119873  0.13238233  0.96569523 -0.25967813  0.22185958 -1.03815179], Reward=-1.0\n",
            "Step 27: State=[ 0.99022643  0.13946904  0.92525012 -0.37935763 -0.15298572 -0.20842166], Reward=-1.0\n",
            "Step 28: State=[ 0.99726254  0.07394201  0.9408686  -0.33877172 -0.49146568  0.62703839], Reward=-1.0\n",
            "Step 29: State=[ 0.99886229 -0.04768787  0.98856896 -0.15076941 -0.69626626  1.26612196], Reward=-1.0\n",
            "Step 30: State=[ 0.98201182 -0.18881943  0.99098292  0.13398824 -0.68748921  1.51709161], Reward=-1.0\n",
            "Step 31: State=[ 0.95327559 -0.30210206  0.91127208  0.4118048  -0.44930373  1.31714919], Reward=-1.0\n",
            "Step 32: State=[ 0.94030304 -0.34033835  0.82113137  0.57073924  0.0543936   0.48661511], Reward=-1.0\n",
            "Step 33: State=[ 0.95591976 -0.29362801  0.79784503  0.60286259  0.42851628 -0.08877581], Reward=-1.0\n",
            "Step 34: State=[ 0.98547536 -0.16981847  0.85531737  0.51810443  0.81855595 -0.90759167], Reward=-1.0\n",
            "Step 35: State=[ 0.99999689  0.00249338  0.94416268  0.32947965  0.8726937  -1.12138394], Reward=-1.0\n",
            "Step 36: State=[ 0.98482443  0.17355354  0.99602693  0.08905254  0.80468521 -1.27422293], Reward=-1.0\n",
            "Step 37: State=[ 0.94891104  0.31554372  0.98398193 -0.17826821  0.62329897 -1.34000462], Reward=-1.0\n",
            "Step 38: State=[ 0.92706591  0.3748984   0.93817082 -0.34617267 -0.00556647 -0.3707513 ], Reward=-1.0\n",
            "Step 39: State=[ 0.94974669  0.31301953  0.94818345 -0.31772337 -0.63987353  0.65997129], Reward=-1.0\n",
            "Step 40: State=[ 0.98634298  0.16470435  0.98535417 -0.17052029 -0.85459012  0.81231466], Reward=-1.0\n",
            "Step 41: State=[ 0.99942501 -0.03390634  0.99885564  0.04782691 -1.09142816  1.30843844], Reward=-1.0\n",
            "Step 42: State=[ 0.96905611 -0.24684055  0.94989495  0.31256933 -1.01148923  1.30973524], Reward=-1.0\n",
            "Step 43: State=[ 0.92347053 -0.38366936  0.88876782  0.45835767 -0.40303565  0.23719778], Reward=-1.0\n",
            "Step 44: State=[ 0.90914155 -0.41648726  0.89013797  0.45569112  0.05086942 -0.26924715], Reward=-1.0\n",
            "Step 45: State=[ 0.93065768 -0.36589109  0.93162907  0.36341062  0.48614461 -0.72166551], Reward=-1.0\n",
            "Step 46: State=[ 0.97637153 -0.21609865  0.99153305  0.12985457  1.04524932 -1.63680507], Reward=-1.0\n",
            "Step 47: State=[ 0.99999221 -0.00394653  0.98414569 -0.17736195  1.03980715 -1.35763132], Reward=-1.0\n",
            "Step 48: State=[ 0.98188698  0.18946754  0.91567613 -0.40191695  0.86080382 -0.92786341], Reward=-1.0\n",
            "Step 49: State=[ 0.94359104  0.33111319  0.84663836 -0.53216866  0.57659641 -0.50834741], Reward=-1.0\n",
            "Step 0: State=[ 0.99992826  0.01197786  0.99303898 -0.11778614  0.14892618 -0.21484159], Reward=-1.0\n",
            "Step 1: State=[ 0.99972539  0.02343381  0.99382584 -0.11095135 -0.03623077  0.28372933], Reward=-1.0\n",
            "Step 2: State=[ 0.99999913 -0.00131665  0.99996162 -0.00876065 -0.20291429  0.71869696], Reward=-1.0\n",
            "Step 3: State=[ 0.99966145 -0.02601907  0.99547968  0.0949748  -0.03618277  0.29895881], Reward=-1.0\n",
            "Step 4: State=[ 0.99916557 -0.0408431   0.98480392  0.1736699  -0.10642151  0.47902648], Reward=-1.0\n",
            "Step 5: State=[ 0.99862263 -0.0524675   0.97020318  0.24229278 -0.00589848  0.20983343], Reward=-1.0\n",
            "Step 6: State=[ 0.99956215 -0.02958902  0.97551198  0.21994629  0.22934539 -0.43188678], Reward=-1.0\n",
            "Step 7: State=[ 0.99939843  0.0346812   0.99678674  0.0801012   0.3963599  -0.9502597 ], Reward=-1.0\n",
            "Step 8: State=[ 0.99430712  0.10655208  0.99440853 -0.1056015   0.3036397  -0.86587083], Reward=-1.0\n",
            "Step 9: State=[ 0.98894409  0.14828885  0.96888208 -0.24752274  0.10475021 -0.5474177 ], Reward=-1.0\n",
            "Step 10: State=[ 0.98743885  0.15800161  0.93939628 -0.34283323 -0.01126491 -0.43284177], Reward=-1.0\n",
            "Step 11: State=[ 0.99146585  0.13036669  0.92704043 -0.37496139 -0.26250795  0.08891553], Reward=-1.0\n",
            "Step 12: State=[ 0.99747986  0.07095017  0.93869965 -0.34473608 -0.32174072  0.22073333], Reward=-1.0\n",
            "Step 13: State=[ 0.99998701 -0.00509736  0.96393988 -0.26612009 -0.42171495  0.58031981], Reward=-1.0\n",
            "Step 14: State=[ 0.99599823 -0.08937293  0.99120048 -0.13236924 -0.40126936  0.74969964], Reward=-1.0\n",
            "Step 15: State=[ 0.98768144 -0.15647801  0.99988847  0.01493508 -0.25690844  0.69144191], Reward=-1.0\n",
            "Step 16: State=[ 0.98271369 -0.18513188  0.99145431  0.13045442 -0.02473061  0.44372139], Reward=-1.0\n",
            "Step 17: State=[ 0.98842705 -0.15169695  0.98849826  0.15123225  0.35716804 -0.23148423], Reward=-1.0\n",
            "Step 18: State=[ 0.99710898 -0.07598476  0.99352185  0.11364122  0.38861371 -0.12980817], Reward=-1.0\n",
            "Step 19: State=[ 0.99995344  0.00965001  0.99737983  0.07234273  0.44970578 -0.26448804], Reward=-1.0\n",
            "Step 20: State=[ 0.994069    0.10875122  0.99986016 -0.01672294  0.52042449 -0.59563205], Reward=-1.0\n",
            "Step 21: State=[ 0.97850092  0.20624244  0.98864829 -0.15024834  0.44322622 -0.70700736], Reward=-1.0\n",
            "Step 22: State=[ 0.96181798  0.27368991  0.95987454 -0.28042978  0.23414419 -0.59520235], Reward=-1.0\n",
            "Step 23: State=[ 0.95645875  0.29186755  0.92930629 -0.36930992 -0.05068496 -0.32782812], Reward=-1.0\n",
            "Step 24: State=[ 0.97033258  0.24177404  0.92931316 -0.36929263 -0.45846818  0.32088082], Reward=-1.0\n",
            "Step 25: State=[ 0.99109625  0.13314736  0.95764088 -0.28796519 -0.6235667   0.51078822], Reward=-1.0\n",
            "Step 26: State=[ 0.99998105  0.00615691  0.98229208 -0.187356   -0.62135493  0.48797457], Reward=-1.0\n",
            "Step 27: State=[ 0.99158502 -0.12945716  0.99904884 -0.0436052  -0.7064218   0.91413122], Reward=-1.0\n",
            "Step 28: State=[ 0.96574947 -0.25947632  0.987989    0.15452422 -0.58735346  1.01843702], Reward=-1.0\n",
            "Step 29: State=[ 0.94288829 -0.33310911  0.95274849  0.30376028 -0.16539054  0.48273872], Reward=-1.0\n",
            "Step 30: State=[ 0.94343189 -0.33156638  0.93085826  0.36538048  0.18299551  0.16142732], Reward=-1.0\n",
            "Step 31: State=[ 0.96410316 -0.26552795  0.93135135  0.36412176  0.49565241 -0.16617407], Reward=-1.0\n",
            "Step 32: State=[ 0.99256545 -0.12171209  0.96953294  0.24496099  0.93940724 -1.04663403], Reward=-1.0\n",
            "Step 33: State=[ 0.99599423  0.08941753  0.99978196 -0.02088138  1.1245591  -1.55509047], Reward=-1.0\n",
            "Step 34: State=[ 0.95774846  0.28760718  0.95465738 -0.29770672  0.84874081 -1.17986317], Reward=-1.0\n",
            "Step 35: State=[ 0.92091381  0.38976628  0.90680189 -0.42155704  0.21606076 -0.12065084], Reward=-1.0\n",
            "Step 36: State=[ 0.92096042  0.38965615  0.91551949 -0.40227362 -0.21630269  0.32842763], Reward=-1.0\n",
            "Step 37: State=[ 0.95392224  0.30005393  0.96216324 -0.27247368 -0.71745947  1.0200667 ], Reward=-1.0\n",
            "Step 38: State=[ 0.99024726  0.13932111  0.99814935 -0.0608101  -0.89261362  1.06880329], Reward=-1.0\n",
            "Step 39: State=[ 0.99812492 -0.0612098   0.98147139  0.19160875 -1.06792217  1.38808723], Reward=-1.0\n",
            "Step 40: State=[ 0.97131276 -0.23780566  0.92376627  0.38295677 -0.68110637  0.55884012], Reward=-1.0\n",
            "Step 41: State=[ 0.94022937 -0.34054182  0.89199067  0.45205381 -0.37076078  0.17817143], Reward=-1.0\n",
            "Step 42: State=[ 0.93699649 -0.34933878  0.92388123  0.38267933  0.27793822 -0.93278658], Reward=-1.0\n",
            "Step 43: State=[ 0.96437047 -0.26455547  0.98452484  0.17524508  0.58898365 -1.18425139], Reward=-1.0\n",
            "Step 44: State=[ 0.99272996 -0.12036286  0.99581086 -0.09143704  0.84325616 -1.42230927], Reward=-1.0\n",
            "Step 45: State=[ 0.99924909  0.03874602  0.94694682 -0.32139029  0.71267194 -0.87096088], Reward=-1.0\n",
            "Step 46: State=[ 0.98658364  0.16325662  0.89884727 -0.438262    0.51203004 -0.35719581], Reward=-1.0\n",
            "Step 47: State=[ 0.97262034  0.23239981  0.89601993 -0.44401384  0.17931657  0.30282435], Reward=-1.0\n",
            "Step 48: State=[ 0.97588988  0.21826347  0.95523979 -0.29583262 -0.3192676   1.27094861], Reward=-1.0\n",
            "Step 49: State=[ 0.99188071  0.12717176  0.99998768 -0.004964   -0.57645623  1.61596656], Reward=-1.0\n",
            "Step 0: State=[ 0.99644837  0.08420594  0.99995181  0.00981677 -0.17620314  0.57035366], Reward=-1.0\n",
            "Step 1: State=[ 0.99851671  0.05444604  0.9958426   0.09109069 -0.11378977  0.22553944], Reward=-1.0\n",
            "Step 2: State=[ 0.99960817  0.02799131  0.99160421  0.12931007 -0.14446378  0.14840548], Reward=-1.0\n",
            "Step 3: State=[ 0.99991985  0.01266059  0.9936776   0.11227126 -0.0064018  -0.31917958], Reward=-1.0\n",
            "Step 4: State=[ 0.99999864 -0.00165163  0.99721521  0.07457769 -0.13487902 -0.05537881], Reward=-1.0\n",
            "Step 5: State=[ 0.99922994 -0.03923679  0.99599877  0.08936689 -0.23284113  0.19509217], Reward=-1.0\n",
            "Step 6: State=[ 0.99701897 -0.07715686  0.99364247  0.11258168 -0.13875979  0.02872271], Reward=-1.0\n",
            "Step 7: State=[ 0.99687135 -0.07904124  0.99791578  0.06452977  0.11851625 -0.5027366 ], Reward=-1.0\n",
            "Step 8: State=[ 0.99823055 -0.05946232  0.99993549 -0.0113585   0.07145386 -0.24063189], Reward=-1.0\n",
            "Step 9: State=[ 0.99862976 -0.05233158  0.99962574 -0.02735638 -0.00182181  0.08414201], Reward=-1.0\n",
            "Step 10: State=[ 0.99943943 -0.03347863  0.99887625 -0.04739454  0.18580814 -0.27778729], Reward=-1.0\n",
            "Step 11: State=[ 0.99996577 -0.00827455  0.99796754 -0.06372435  0.06089245  0.12047398], Reward=-1.0\n",
            "Step 12: State=[ 9.99951140e-01 -9.88522285e-03  9.99999999e-01 -3.18278819e-05\n",
            " -7.44975133e-02  5.05270317e-01], Reward=-1.0\n",
            "Step 13: State=[ 0.99936898 -0.0355196   0.99152379  0.12992527 -0.17213151  0.77066076], Reward=-1.0\n",
            "Step 14: State=[ 0.99728386 -0.07365388  0.95681387  0.29070126 -0.19650994  0.84130273], Reward=-1.0\n",
            "Step 15: State=[ 0.99409258 -0.10853544  0.89921757  0.43750173 -0.14258345  0.7070157 ], Reward=-1.0\n",
            "Step 16: State=[ 0.99342852 -0.11445429  0.86031755  0.50975848  0.08435966  0.10367566], Reward=-1.0\n",
            "Step 17: State=[ 0.99605126 -0.08877997  0.86435588  0.50288062  0.16809681 -0.17806041], Reward=-1.0\n",
            "Step 18: State=[ 0.99928143 -0.03790283  0.90689547  0.42135567  0.33016004 -0.72202506], Reward=-1.0\n",
            "Step 19: State=[ 0.9987573   0.04983837  0.97665048  0.21483447  0.52575338 -1.4170926 ], Reward=-1.0\n",
            "Step 20: State=[ 0.98714943  0.15979989  0.99435061 -0.1061455   0.5459006  -1.73517757], Reward=-1.0\n",
            "Step 21: State=[ 0.96810011  0.2505637   0.90302678 -0.42958426  0.35037653 -1.56780911], Reward=-1.0\n",
            "Step 22: State=[ 0.96460099  0.26371374  0.79899639 -0.60133582 -0.21524661 -0.42332971], Reward=-1.0\n",
            "Step 23: State=[ 0.98532711  0.17067656  0.81802759 -0.57517898 -0.71750985  0.73067784], Reward=-1.0\n",
            "Step 24: State=[ 0.99996525 -0.00833602  0.9336324  -0.35823253 -1.04254567  1.67734945], Reward=-1.0\n",
            "Step 25: State=[ 0.97749639 -0.21095216  0.99995322 -0.00967283 -0.94649041  1.79204897], Reward=-1.0\n",
            "Step 26: State=[ 0.93832969 -0.3457418   0.96180151  0.27374778 -0.42285625  1.01033167], Reward=-1.0\n",
            "Step 27: State=[ 0.9263877  -0.37657115  0.91661462  0.39977198  0.1007372   0.30698137], Reward=-1.0\n",
            "Step 28: State=[ 0.95118458 -0.30862258  0.9221206   0.38690258  0.60822435 -0.43648288], Reward=-1.0\n",
            "Step 29: State=[ 0.9902162  -0.13954166  0.977237    0.21215053  1.0907682  -1.34705329], Reward=-1.0\n",
            "Step 30: State=[ 0.99607988  0.0884583   0.99714688 -0.07548581  1.1387239  -1.45578056], Reward=-1.0\n",
            "Step 31: State=[ 0.96116666  0.27596859  0.95593509 -0.29357812  0.72809724 -0.70463952], Reward=-1.0\n",
            "Step 32: State=[ 0.93342098  0.35878304  0.94240526 -0.33447321  0.12859959  0.28883319], Reward=-1.0\n",
            "Step 33: State=[ 0.94196064  0.33572332  0.97628644 -0.21648278 -0.36627232  0.91675612], Reward=-1.0\n",
            "Step 34: State=[ 0.9709929   0.23910833  0.99970203 -0.02441007 -0.6167866   0.9731091 ], Reward=-1.0\n",
            "Step 35: State=[ 0.99666613  0.08158809  0.97634008  0.21624074 -0.94021454  1.38060736], Reward=-1.0\n",
            "Step 36: State=[ 0.99474724 -0.10236176  0.89529984  0.44546402 -0.85896757  0.9892884 ], Reward=-1.0\n",
            "Step 37: State=[ 0.96981508 -0.24384155  0.82994785  0.55784099 -0.54865565  0.27626695], Reward=-1.0\n",
            "Step 38: State=[ 0.95151798 -0.30759312  0.84522077  0.5344173  -0.10158045 -0.5599664 ], Reward=-1.0\n",
            "Step 39: State=[ 0.95587848 -0.29376238  0.91911108  0.3939985   0.23986759 -1.00276604], Reward=-1.0\n",
            "Step 40: State=[ 0.98075711 -0.19523188  0.99393672  0.10995362  0.74861311 -1.88414474], Reward=-1.0\n",
            "Step 41: State=[ 0.9990811  -0.04285967  0.9704763  -0.2411965   0.74363382 -1.56484952], Reward=-1.0\n",
            "Step 42: State=[ 0.99389262  0.11035154  0.85184324 -0.5237968   0.75120778 -1.43755198], Reward=-1.0\n",
            "Step 43: State=[ 0.9733872   0.22916664  0.72372774 -0.69008562  0.43173676 -0.62929508], Reward=-1.0\n",
            "Step 44: State=[ 0.95874605  0.28426399  0.67849536 -0.73460469  0.127343    0.00695518], Reward=-1.0\n",
            "Step 45: State=[ 0.9642527   0.26498441  0.74740999 -0.66436308 -0.32541513  0.96808431], Reward=-1.0\n",
            "Step 46: State=[ 0.98682475  0.16179283  0.90156997 -0.43263332 -0.70869914  1.77867316], Reward=-1.0\n",
            "Step 47: State=[ 0.99990277 -0.01394478  0.99994607 -0.01038533 -1.00473691  2.486968  ], Reward=-1.0\n",
            "Step 48: State=[ 0.98002069 -0.19889556  0.89618775  0.44367501 -0.80180988  2.09774948], Reward=-1.0\n",
            "Step 49: State=[ 0.94623035 -0.32349362  0.6782775   0.73480585 -0.46007139  1.49777347], Reward=-1.0\n",
            "Step 0: State=[ 0.99994975  0.01002522  0.99866223 -0.05170832 -0.18136579  0.36457008], Reward=-1.0\n",
            "Step 1: State=[ 0.99921148 -0.03970412  0.99831752  0.05798385 -0.30226356  0.70575147], Reward=-1.0\n",
            "Step 2: State=[ 0.99587929 -0.09068872  0.98338473  0.18153366 -0.19475166  0.51077003], Reward=-1.0\n",
            "Step 3: State=[ 0.99360113 -0.112946    0.96817661  0.25026797 -0.02285881  0.17903265], Reward=-1.0\n",
            "Step 4: State=[ 0.99629549 -0.08599595  0.97641779  0.21588955  0.28703945 -0.52246889], Reward=-1.0\n",
            "Step 5: State=[ 0.99999181 -0.00404803  0.9985421   0.05397841  0.51196601 -1.07316879], Reward=-1.0\n",
            "Step 6: State=[ 0.99556822  0.09404208  0.98790496 -0.15506061  0.44355062 -0.97159718], Reward=-1.0\n",
            "Step 7: State=[ 0.9886909   0.14996768  0.96058888 -0.27797304  0.10624696 -0.26147785], Reward=-1.0\n",
            "Step 8: State=[ 0.9871508   0.15979144  0.94820482 -0.31765959 -0.00984619 -0.1462238 ], Reward=-1.0\n",
            "Step 9: State=[ 0.99110678  0.13306896  0.95393286 -0.30002016 -0.25411815  0.32446946], Reward=-1.0\n",
            "Step 10: State=[ 0.99706474  0.07656308  0.97266392 -0.23221735 -0.30059176  0.3587196 ], Reward=-1.0\n",
            "Step 11: State=[ 0.99981823  0.01906609  0.98559211 -0.16913955 -0.26152259  0.26542698], Reward=-1.0\n",
            "Step 12: State=[ 0.9987817  -0.0493469   0.99776046 -0.06688851 -0.40580294  0.736583  ], Reward=-1.0\n",
            "Step 13: State=[ 0.99262979 -0.12118622  0.9971868   0.07495658 -0.29640441  0.6474292 ], Reward=-1.0\n",
            "Step 14: State=[ 0.98700767 -0.16067313  0.98398325  0.17826097 -0.09161219  0.371384  ], Reward=-1.0\n",
            "Step 15: State=[ 0.98578253 -0.16802622  0.9685735   0.24872752  0.02075561  0.33676564], Reward=-1.0\n",
            "Step 16: State=[ 0.99028286 -0.13906784  0.96223058  0.27223576  0.26666149 -0.09237243], Reward=-1.0\n",
            "Step 17: State=[ 0.99856294 -0.05359159  0.98298146  0.18370479  0.5724437  -0.78971562], Reward=-1.0\n",
            "Step 18: State=[ 0.9969322   0.07826993  0.99974409 -0.02262193  0.71382867 -1.22694618], Reward=-1.0\n",
            "Step 19: State=[ 0.97660696  0.21503221  0.96136785 -0.27526687  0.63336551 -1.26846715], Reward=-1.0\n",
            "Step 20: State=[ 0.94982403  0.31278478  0.87526079 -0.48365127  0.35514784 -0.94260746], Reward=-1.0\n",
            "Step 21: State=[ 0.94296966  0.33287869  0.8200523  -0.57228858 -0.14676475 -0.08891947], Reward=-1.0\n",
            "Step 22: State=[ 0.96906042  0.24682361  0.87352219 -0.48678434 -0.73472589  1.07735629], Reward=-1.0\n",
            "Step 23: State=[ 0.99834209  0.05755921  0.98093126 -0.19435498 -1.13893297  1.97687231], Reward=-1.0\n",
            "Step 24: State=[ 0.98786969 -0.15528513  0.98542672  0.17010053 -0.9393904   1.58485363], Reward=-1.0\n",
            "Step 25: State=[ 0.95568259 -0.29439902  0.91938643  0.39335555 -0.45743935  0.6955998 ], Reward=-1.0\n",
            "Step 26: State=[ 0.93720562 -0.34877732  0.87603426  0.48224887 -0.10429038  0.27336724], Reward=-1.0\n",
            "Step 27: State=[ 0.94327091 -0.33202409  0.87300161  0.48771733  0.27885456 -0.20930757], Reward=-1.0\n",
            "Step 28: State=[ 0.96908883 -0.24671206  0.91134374  0.4116462   0.5935294  -0.61933057], Reward=-1.0\n",
            "Step 29: State=[ 0.99632542 -0.08564842  0.97836543  0.20688424  1.00455454 -1.48377985], Reward=-1.0\n",
            "Step 30: State=[ 0.99287362  0.11917202  0.99479473 -0.10189916  0.99511796 -1.5304503 ], Reward=-1.0\n",
            "Step 31: State=[ 0.95394255  0.29998936  0.92031306 -0.39118267  0.81089904 -1.38833718], Reward=-1.0\n",
            "Step 32: State=[ 0.9097924   0.41506359  0.8075436  -0.58980788  0.39534862 -0.8560837 ], Reward=-1.0\n",
            "Step 33: State=[ 0.90300636  0.42962719  0.76394494 -0.64528143 -0.2367132   0.15731023], Reward=-1.0\n",
            "Step 34: State=[ 0.94776852  0.31895897  0.85856215 -0.51270951 -0.93594802  1.44824331], Reward=-1.0\n",
            "Step 35: State=[ 0.99642058  0.08453423  0.98972021 -0.14301714 -1.40767902  2.40461738], Reward=-1.0\n",
            "Step 36: State=[ 0.9784639  -0.20641802  0.93333788  0.35899917 -1.43613781  2.54846923], Reward=-1.0\n",
            "Step 37: State=[ 0.90684048 -0.42147401  0.72697233  0.68666675 -0.79238712  1.28343614], Reward=-1.0\n",
            "Step 38: State=[ 0.8704712  -0.49221935  0.64559037  0.76368389  0.00800825 -0.170852  ], Reward=-1.0\n",
            "Step 39: State=[ 0.89836848 -0.43924261  0.73126555  0.68209288  0.57993863 -0.99796615], Reward=-1.0\n",
            "Step 40: State=[ 0.95782582 -0.28734945  0.8861788   0.46334344  1.01865495 -1.63934243], Reward=-1.0\n",
            "Step 41: State=[ 0.99919026 -0.04023454  0.99831276  0.05806573  1.43121419 -2.48753473], Reward=-1.0\n",
            "Step 42: State=[ 0.97227426  0.23384345  0.91322773 -0.40744951  1.25792078 -2.15404332], Reward=-1.0\n",
            "Step 43: State=[ 0.90017537  0.43552762  0.7016968  -0.71247569  0.84226637 -1.50679881], Reward=-1.0\n",
            "Step 44: State=[ 0.85879471  0.51231986  0.58538781 -0.81075342  0.01975547 -0.00905767], Reward=-1.0\n",
            "Step 45: State=[ 0.89178359  0.45246219  0.67736751 -0.73564479 -0.6930089   1.18698929], Reward=-1.0\n",
            "Step 46: State=[ 0.9670663   0.25452458  0.9009416  -0.43394036 -1.39073834  2.53601012], Reward=-1.0\n",
            "Step 47: State=[ 0.99885999 -0.04773586  0.99412614  0.10822765 -1.57450093  2.8731846 ], Reward=-1.0\n",
            "Step 48: State=[ 0.94418812 -0.32940673  0.80824656  0.5888442  -1.23264008  2.2074133 ], Reward=-1.0\n",
            "Step 49: State=[ 0.86197209 -0.50695574  0.54970463  0.83535909 -0.69196372  1.33527639], Reward=-1.0\n",
            "Step 0: State=[ 0.99888746 -0.04715758  0.99565616  0.09310645 -0.09507277  0.25482748], Reward=-1.0\n",
            "Step 1: State=[ 0.99833902 -0.05761253  0.99183156  0.12755451 -0.00659818  0.08454278], Reward=-1.0\n",
            "Step 2: State=[ 0.9980361  -0.06264134  0.98723757  0.15925442 -0.04166222  0.22929888], Reward=-1.0\n",
            "Step 3: State=[ 0.99733475 -0.07296163  0.97678717  0.21421212 -0.05787291  0.31888502], Reward=-1.0\n",
            "Step 4: State=[ 0.99748032 -0.07094374  0.96928963  0.24592196  0.07829525  0.00244369], Reward=-1.0\n",
            "Step 5: State=[ 0.9990765  -0.04296672  0.97638496  0.21603798  0.19527037 -0.30007164], Reward=-1.0\n",
            "Step 6: State=[ 0.99999475  0.00324028  0.99092553  0.13441201  0.25511336 -0.50816829], Reward=-1.0\n",
            "Step 7: State=[ 0.99918512  0.04036217  0.99826239  0.05892538  0.10644641 -0.23177538], Reward=-1.0\n",
            "Step 8: State=[ 0.99905784  0.04339848  0.99890399  0.04680624 -0.07680054  0.11252574], Reward=-1.0\n",
            "Step 9: State=[ 0.99993759  0.01117175  0.99485567  0.10130253 -0.23709086  0.41905864], Reward=-1.0\n",
            "Step 10: State=[ 0.99892248 -0.04640998  0.97895787  0.20406244 -0.32374943  0.59390066], Reward=-1.0\n",
            "Step 11: State=[ 0.99515961 -0.09827183  0.95742664  0.2886767  -0.18375435  0.25809393], Reward=-1.0\n",
            "Step 12: State=[ 0.99323773 -0.11609826  0.95439353  0.2985515   0.00809041 -0.15856458], Reward=-1.0\n",
            "Step 13: State=[ 0.99410691 -0.10840411  0.9650364   0.26211591  0.06661681 -0.213481  ], Reward=-1.0\n",
            "Step 14: State=[ 0.9978846  -0.06501016  0.98823759  0.15292636  0.35722652 -0.87878975], Reward=-1.0\n",
            "Step 15: State=[ 9.99999996e-01 -8.90115162e-05  9.99998727e-01 -1.59589308e-03\n",
            "  2.74204964e-01 -6.35193981e-01], Reward=-1.0\n",
            "Step 16: State=[ 0.99866786  0.05159949  0.99254102 -0.12191112  0.22870593 -0.54228368], Reward=-1.0\n",
            "Step 17: State=[ 0.99733033  0.07302203  0.98489945 -0.17312733 -0.01938176  0.03532676], Reward=-1.0\n",
            "Step 18: State=[ 0.99750992  0.07052636  0.98438921 -0.17600534 -0.00526628 -0.06434303], Reward=-1.0\n",
            "Step 19: State=[ 0.99833322  0.05771292  0.98644286 -0.16410508 -0.1200267   0.18085694], Reward=-1.0\n",
            "Step 20: State=[ 0.99968868  0.02495093  0.99412088 -0.10827591 -0.19947995  0.36803804], Reward=-1.0\n",
            "Step 21: State=[ 0.99984056 -0.01785658  0.99968184 -0.02522324 -0.21735115  0.44359222], Reward=-1.0\n",
            "Step 22: State=[ 0.99751525 -0.07045087  0.99556485  0.09407779 -0.29448377  0.72151045], Reward=-1.0\n",
            "Step 23: State=[ 0.99331513 -0.11543416  0.97691134  0.21364512 -0.1448631   0.46253637], Reward=-1.0\n",
            "Step 24: State=[ 0.99219646 -0.12468431  0.96343442  0.26794423  0.05468507  0.08720025], Reward=-1.0\n",
            "Step 25: State=[ 0.99668517 -0.08135526  0.97681118  0.21410261  0.3705263  -0.62652457], Reward=-1.0\n",
            "Step 26: State=[ 0.99994479 -0.010508    0.99485644  0.10129495  0.32088889 -0.4857425 ], Reward=-1.0\n",
            "Step 27: State=[ 0.99918817  0.04028655  0.99947036  0.03254236  0.1748771  -0.1839304 ], Reward=-1.0\n",
            "Step 28: State=[ 0.99659371  0.08246804  0.99936021 -0.03576563  0.23695469 -0.48069909], Reward=-1.0\n",
            "Step 29: State=[ 0.99319828  0.11643533  0.99330755 -0.11549938  0.09526995 -0.30057927], Reward=-1.0\n",
            "Step 30: State=[ 0.99136371  0.13114109  0.98297993 -0.18371297  0.04772796 -0.37524993], Reward=-1.0\n",
            "Step 31: State=[ 0.99419622  0.10758199  0.98161903 -0.19085093 -0.27989373  0.29942036], Reward=-1.0\n",
            "Step 32: State=[ 0.99928062  0.03792427  0.99435207 -0.10613178 -0.4018861   0.53220686], Reward=-1.0\n",
            "Step 33: State=[ 0.99949548 -0.03176141  0.9996648  -0.02588987 -0.27859891  0.24763081], Reward=-1.0\n",
            "Step 34: State=[ 0.99668188 -0.08139555  0.99980247  0.01987527 -0.20718729  0.19463343], Reward=-1.0\n",
            "Step 35: State=[ 0.99387709 -0.11049131  0.99891462  0.04657886 -0.0785644   0.06376896], Reward=-1.0\n",
            "Step 36: State=[ 0.9922364  -0.12436609  0.9969796   0.07766391 -0.05732678  0.24008374], Reward=-1.0\n",
            "Step 37: State=[ 0.99442828 -0.10541531  0.99754514  0.07002643  0.24362072 -0.31178924], Reward=-1.0\n",
            "Step 38: State=[ 0.99897855 -0.04518681  0.99998501 -0.00547532  0.34580226 -0.42130925], Reward=-1.0\n",
            "Step 39: State=[ 0.99966371  0.02593181  0.99611938 -0.0880124   0.34858769 -0.37992552], Reward=-1.0\n",
            "Step 40: State=[ 0.99617338  0.08739911  0.98911254 -0.14716111  0.25305984 -0.19650675], Reward=-1.0\n",
            "Step 41: State=[ 0.99250737  0.12218481  0.98709112 -0.1601597   0.08951561  0.07199193], Reward=-1.0\n",
            "Step 42: State=[ 0.99256999  0.12167503  0.9929608  -0.11844344 -0.09309223  0.34176071], Reward=-1.0\n",
            "Step 43: State=[ 0.99492056  0.10066315  0.99794023 -0.06415059 -0.11234581  0.19091332], Reward=-1.0\n",
            "Step 44: State=[ 0.9978141   0.0660835   0.99992559 -0.01219911 -0.22593198  0.31459009], Reward=-1.0\n",
            "Step 45: State=[ 0.99988796  0.01496862  0.99852063  0.05437421 -0.27321414  0.33195133], Reward=-1.0\n",
            "Step 46: State=[ 0.99928568 -0.03779051  0.99368379  0.11221643 -0.24205696  0.23059665], Reward=-1.0\n",
            "Step 47: State=[ 0.99590962 -0.09035503  0.98481201  0.17362406 -0.27205749  0.37097199], Reward=-1.0\n",
            "Step 48: State=[ 0.99340443 -0.1146632   0.98307387  0.18320962  0.03249186 -0.2779633 ], Reward=-1.0\n",
            "Step 49: State=[ 0.99579649 -0.09159336  0.9948663   0.10119801  0.19213177 -0.53304108], Reward=-1.0\n",
            "Step 0: State=[ 0.99812391  0.06122624  0.99963385  0.02705857 -0.0194682  -0.43721651], Reward=-1.0\n",
            "Step 1: State=[ 0.99932369  0.03677186  0.99979363 -0.02031472 -0.22163983 -0.0326298 ], Reward=-1.0\n",
            "Step 2: State=[ 0.99971538 -0.02385711  0.99993095  0.01175097 -0.37122163  0.3379506 ], Reward=-1.0\n",
            "Step 3: State=[ 0.99452046 -0.10454215  0.99444882  0.10522137 -0.41807365  0.56962582], Reward=-1.0\n",
            "Step 4: State=[ 0.98780081 -0.15572267  0.98752976  0.15743242 -0.08680574 -0.05831663], Reward=-1.0\n",
            "Step 5: State=[ 0.99048341 -0.13763216  0.99666642  0.08158459  0.26347761 -0.68975743], Reward=-1.0\n",
            "Step 6: State=[ 0.99838004 -0.05689728  0.99447766 -0.10494852  0.52497598 -1.13223821], Reward=-1.0\n",
            "Step 7: State=[ 0.99942423  0.03392934  0.96098753 -0.27659171  0.36108344 -0.57725981], Reward=-1.0\n",
            "Step 8: State=[ 0.99676071  0.08042448  0.9478261  -0.31878783  0.0946581   0.14787241], Reward=-1.0\n",
            "Step 9: State=[ 0.99536013  0.09621961  0.95854034 -0.28495686  0.06174076  0.20352324], Reward=-1.0\n",
            "Step 10: State=[ 0.99692505  0.07836098  0.98434302 -0.17626347 -0.23463647  0.89378456], Reward=-1.0\n",
            "Step 11: State=[ 0.99939337  0.03482653  0.99989306 -0.01462427 -0.18705796  0.69640429], Reward=-1.0\n",
            "Step 12: State=[ 0.99984125 -0.01781766  0.98763271  0.1567853  -0.3226307   0.98497995], Reward=-1.0\n",
            "Step 13: State=[ 0.99819506 -0.06005513  0.95723271  0.28931908 -0.08886821  0.34918644], Reward=-1.0\n",
            "Step 14: State=[ 0.99701682 -0.07718461  0.9362231   0.35140619 -0.07760836  0.29319843], Reward=-1.0\n",
            "Step 15: State=[ 0.99798242 -0.0634908   0.94300349  0.33278284  0.21143379 -0.48598841], Reward=-1.0\n",
            "Step 16: State=[ 0.99995189 -0.0098089   0.97875722  0.2050227   0.31150709 -0.81219574], Reward=-1.0\n",
            "Step 17: State=[ 0.99773738  0.06723183  0.99998766 -0.00496757  0.43696327 -1.25367835], Reward=-1.0\n",
            "Step 18: State=[ 0.98815592  0.1534532   0.96349705 -0.26771896  0.40328619 -1.34505081], Reward=-1.0\n",
            "Step 19: State=[ 0.97631617  0.21634864  0.86840034 -0.49586375  0.21712348 -1.08438727], Reward=-1.0\n",
            "Step 20: State=[ 0.97239282  0.23334994  0.77143516 -0.63630794 -0.04773123 -0.60118218], Reward=-1.0\n",
            "Step 21: State=[ 0.98014634  0.19827542  0.72866619 -0.68486903 -0.30345957 -0.04508114], Reward=-1.0\n",
            "Step 22: State=[ 0.99287839  0.11913226  0.75771263 -0.65258837 -0.4810742   0.46231997], Reward=-1.0\n",
            "Step 23: State=[ 0.99996047 -0.00889194  0.87000008 -0.49305158 -0.77669719  1.45463212], Reward=-1.0\n",
            "Step 24: State=[ 0.98643426 -0.1641568   0.98270617 -0.18517175 -0.74367398  1.76133048], Reward=-1.0\n",
            "Step 25: State=[ 0.95848121 -0.28515571  0.98821023  0.15310307 -0.46143619  1.55723287], Reward=-1.0\n",
            "Step 26: State=[ 0.94781639 -0.31881669  0.9304248   0.36648286  0.11970741  0.62090827], Reward=-1.0\n",
            "Step 27: State=[ 0.9707644  -0.24003434  0.92253922  0.38590334  0.68414547 -0.40308886], Reward=-1.0\n",
            "Step 28: State=[ 0.99805354 -0.06236295  0.9746916   0.22355378  1.07565201 -1.2520773 ], Reward=-1.0\n",
            "Step 29: State=[ 0.98601746  0.16664204  0.99726146 -0.07395662  1.1659729  -1.65045862], Reward=-1.0\n",
            "Step 30: State=[ 0.93336125  0.35893841  0.93561073 -0.35303337  0.78433487 -1.14166734], Reward=-1.0\n",
            "Step 31: State=[ 0.88714014  0.46150014  0.85665213 -0.5158945   0.31720492 -0.63387965], Reward=-1.0\n",
            "Step 32: State=[ 0.8887762   0.45834143  0.84030403 -0.54211543 -0.35171669  0.32727005], Reward=-1.0\n",
            "Step 33: State=[ 0.94551644  0.32557436  0.92749036 -0.37384707 -1.06505052  1.53493363], Reward=-1.0\n",
            "Step 34: State=[ 0.99764429  0.06859938  0.9999159   0.01296919 -1.49966662  2.31520429], Reward=-1.0\n",
            "Step 35: State=[ 0.97523956 -0.22115108  0.89999201  0.4359064  -1.34352746  1.93757075], Reward=-1.0\n",
            "Step 36: State=[ 0.8977575  -0.44049004  0.71074695  0.70344777 -0.93994721  1.28617354], Reward=-1.0\n",
            "Step 37: State=[ 0.83381445 -0.5520448   0.58256514  0.81278402 -0.32541352  0.38095732], Reward=-1.0\n",
            "Step 38: State=[ 0.84145855 -0.54032166  0.62171298  0.78324515  0.463769   -0.86821436], Reward=-1.0\n",
            "Step 39: State=[ 0.91932506 -0.39349897  0.82149577  0.57021461  1.17230867 -2.02810529], Reward=-1.0\n",
            "Step 40: State=[ 0.99418518 -0.1076839   0.99647292  0.08391494  1.72101793 -3.0708122 ], Reward=-1.0\n",
            "Step 41: State=[ 0.97626636  0.21657329  0.88797241 -0.45989672  1.45408519 -2.3853028 ], Reward=-1.0\n",
            "Step 42: State=[ 0.89100416  0.45399513  0.63069577 -0.77603019  1.02412692 -1.64270646], Reward=-1.0\n",
            "Step 43: State=[ 0.81761025  0.57577207  0.4376126  -0.89916362  0.37769971 -0.63350199], Reward=-1.0\n",
            "Step 44: State=[ 0.81503637  0.5794098   0.41878193 -0.90808683 -0.33299131  0.42557068], Reward=-1.0\n",
            "Step 45: State=[ 0.88500943  0.46557309  0.58204019 -0.81316002 -0.98346682  1.45019468], Reward=-1.0\n",
            "Step 46: State=[ 0.97457844  0.22404659  0.85731492 -0.51479231 -1.55291591  2.57504668], Reward=-1.0\n",
            "Step 47: State=[ 0.99410982 -0.10837747  0.99946555  0.03268975 -1.70220429  2.98945476], Reward=-1.0\n",
            "Step 48: State=[ 0.92002819 -0.39185217  0.85465028  0.5192041  -1.16656191  2.01364137], Reward=-1.0\n",
            "Step 49: State=[ 0.84276524 -0.5382813   0.66702683  0.7450337  -0.46295624  0.89582549], Reward=-1.0\n",
            "Step 0: State=[ 0.99862341  0.05245278  0.9999902   0.00442823 -0.04368144 -0.02337708], Reward=-1.0\n",
            "Step 1: State=[ 0.99869732  0.05102619  0.99954153 -0.03027756  0.02845335 -0.31764747], Reward=-1.0\n",
            "Step 2: State=[ 0.99804341  0.06252481  0.99306786 -0.11754247  0.08137667 -0.54031681], Reward=-1.0\n",
            "Step 3: State=[ 0.99673988  0.08068215  0.97188907 -0.23543926  0.0929436  -0.63441118], Reward=-1.0\n",
            "Step 4: State=[ 0.99534467  0.09637941  0.93534967 -0.35372446  0.05781795 -0.58143827], Reward=-1.0\n",
            "Step 5: State=[ 0.99604529  0.08884696  0.90945554 -0.41580118 -0.13252573 -0.08372048], Reward=-1.0\n",
            "Step 6: State=[ 0.99895668  0.0456679   0.92270242 -0.38551296 -0.29053632  0.40260785], Reward=-1.0\n",
            "Step 7: State=[ 0.99996032 -0.00890786  0.95244198 -0.30472    -0.2420414   0.43614731], Reward=-1.0\n",
            "Step 8: State=[ 0.99893733 -0.04608916  0.97359385 -0.22828713 -0.12019038  0.33813091], Reward=-1.0\n",
            "Step 9: State=[ 0.99773628 -0.06724816  0.98927378 -0.14607324 -0.08517735  0.4820058 ], Reward=-1.0\n",
            "Step 10: State=[ 0.99698952 -0.07753639  0.99898032 -0.04514771 -0.01282174  0.51349036], Reward=-1.0\n",
            "Step 11: State=[ 0.99834221 -0.05755727  0.99985362  0.01710973  0.21072964  0.10203913], Reward=-1.0\n",
            "Step 12: State=[ 0.99995255 -0.00974166  0.99951757  0.03105829  0.25842777  0.04251308], Reward=-1.0\n",
            "Step 13: State=[0.9991337  0.04161554 0.99932374 0.03677052 0.24502957 0.02157496], Reward=-1.0\n",
            "Step 14: State=[ 0.9952481   0.09737156  0.9999661   0.00823428  0.3016212  -0.29319621], Reward=-1.0\n",
            "Step 15: State=[ 0.98776589  0.15594402  0.99736466 -0.07255154  0.27450911 -0.49220578], Reward=-1.0\n",
            "Step 16: State=[ 0.97975736  0.20018871  0.98414501 -0.17736575  0.16286184 -0.53985446], Reward=-1.0\n",
            "Step 17: State=[ 0.98172989  0.19027986  0.97779568 -0.20956051 -0.26206835  0.2144486 ], Reward=-1.0\n",
            "Step 18: State=[ 0.99186102  0.12732525  0.9861927  -0.16560183 -0.36153062  0.21607985], Reward=-1.0\n",
            "Step 19: State=[ 0.9996388   0.02687504  0.99796692 -0.06373404 -0.62270976  0.77665178], Reward=-1.0\n",
            "Step 20: State=[ 0.99658204 -0.0826089   0.99837779  0.05693665 -0.4473221   0.39305334], Reward=-1.0\n",
            "Step 21: State=[ 0.98556369 -0.1693051   0.98867494  0.15007289 -0.40637037  0.51410827], Reward=-1.0\n",
            "Step 22: State=[ 0.97497937 -0.22229536  0.97666604  0.21476372 -0.12187822  0.12611899], Reward=-1.0\n",
            "Step 23: State=[ 0.97373323 -0.22769188  0.97322259  0.22986472  0.06786663  0.02565981], Reward=-1.0\n",
            "Step 24: State=[ 0.98046295 -0.19670383  0.97433178  0.22511684  0.24273895 -0.06901756], Reward=-1.0\n",
            "Step 25: State=[ 0.99238007 -0.12321446  0.9848981   0.17313504  0.48527553 -0.44155525], Reward=-1.0\n",
            "Step 26: State=[ 9.99999928e-01  3.79301774e-04  9.99604916e-01  2.81071404e-02\n",
            "  7.24086439e-01 -9.72945826e-01], Reward=-1.0\n",
            "Step 27: State=[ 0.99217827  0.12482898  0.99238099 -0.12320703  0.49406523 -0.49831444], Reward=-1.0\n",
            "Step 28: State=[ 0.98225564  0.18754697  0.98750795 -0.15756921  0.12780505  0.1652623 ], Reward=-1.0\n",
            "Step 29: State=[ 0.98243605  0.18659959  0.99575612 -0.09203121 -0.13495871  0.4836009 ], Reward=-1.0\n",
            "Step 30: State=[ 0.98857454  0.15073278  0.99997319 -0.00732307 -0.21892202  0.34466588], Reward=-1.0\n",
            "Step 31: State=[ 0.99695427  0.07798833  0.99431429  0.10648516 -0.49471821  0.76350493], Reward=-1.0\n",
            "Step 32: State=[ 0.99933738 -0.03639786  0.96085158  0.27706359 -0.62101824  0.92793322], Reward=-1.0\n",
            "Step 33: State=[ 0.98951199 -0.14445074  0.91156977  0.41114541 -0.43976863  0.46466403], Reward=-1.0\n",
            "Step 34: State=[ 0.97919206 -0.20293573  0.89779369  0.44041626 -0.14195207 -0.15310288], Reward=-1.0\n",
            "Step 35: State=[ 0.97755841 -0.21066456  0.92275725  0.3853817   0.06291039 -0.44279504], Reward=-1.0\n",
            "Step 36: State=[ 0.98800434 -0.15442611  0.97637135  0.21609949  0.49410916 -1.30096932], Reward=-1.0\n",
            "Step 37: State=[ 0.99967395 -0.02553399  0.994829   -0.10156405  0.7627337  -1.81566172], Reward=-1.0\n",
            "Step 38: State=[ 0.99297716  0.11830623  0.90601469 -0.42324624  0.63928684 -1.45856703], Reward=-1.0\n",
            "Step 39: State=[ 0.97903143  0.20370925  0.80903948 -0.5877543   0.20985467 -0.42402232], Reward=-1.0\n",
            "Step 40: State=[ 0.97770335  0.20999084  0.80601849 -0.59189036 -0.14661985  0.37355992], Reward=-1.0\n",
            "Step 41: State=[ 0.98895663  0.14820518  0.88546053 -0.46471459 -0.46794808  1.10137184], Reward=-1.0\n",
            "Step 42: State=[ 0.99979719  0.0201389   0.98451199 -0.17531726 -0.78567296  1.90438327], Reward=-1.0\n",
            "Step 43: State=[ 0.99103383 -0.13361117  0.9786827   0.20537811 -0.70895954  1.82917729], Reward=-1.0\n",
            "Step 44: State=[ 0.96665813 -0.25607041  0.85102546  0.52512444 -0.50467193  1.55545278], Reward=-1.0\n",
            "Step 45: State=[ 0.9548874  -0.29696811  0.736297    0.6766585   0.08368775  0.33030955], Reward=-1.0\n",
            "Step 46: State=[ 0.96860046 -0.24862248  0.73399502  0.67915485  0.40818646 -0.28995504], Reward=-1.0\n",
            "Step 47: State=[ 0.99269091 -0.12068457  0.84166402  0.54000156  0.86961942 -1.44044231], Reward=-1.0\n",
            "Step 48: State=[ 0.99840131  0.05652285  0.96647541  0.25675919  0.86132814 -1.58804896], Reward=-1.0\n",
            "Step 49: State=[ 0.97631139  0.2163702   0.99793912 -0.0641679   0.71024271 -1.5663    ], Reward=-1.0\n",
            "Step 0: State=[ 0.99992095  0.01257367  0.9997386   0.02286344 -0.05686822  0.37972086], Reward=-1.0\n",
            "Step 1: State=[ 0.99999943  0.00106918  0.99553258  0.09441865 -0.05364004  0.32315724], Reward=-1.0\n",
            "Step 2: State=[ 0.99979241 -0.02037487  0.98364668  0.18010886 -0.15349557  0.52351709], Reward=-1.0\n",
            "Step 3: State=[ 0.99954206 -0.03026009  0.97437994  0.22490826  0.05729038 -0.07392826], Reward=-1.0\n",
            "Step 4: State=[ 0.9996929  -0.02478103  0.97565582  0.21930739 -0.00368663  0.01817945], Reward=-1.0\n",
            "Step 5: State=[ 0.99982839 -0.01852541  0.98009076  0.19855001  0.06432091 -0.22581002], Reward=-1.0\n",
            "Step 6: State=[ 9.99999822e-01 -5.97366506e-04  9.90961287e-01  1.34148154e-01\n",
            "  1.09414517e-01 -4.13650044e-01], Reward=-1.0\n",
            "Step 7: State=[ 0.99974828  0.02243619  0.99914061  0.04144926  0.11337737 -0.49769908], Reward=-1.0\n",
            "Step 8: State=[ 0.99913556  0.04157094  0.99842784 -0.05605215  0.07112702 -0.45792964], Reward=-1.0\n",
            "Step 9: State=[ 0.99937736  0.0352831   0.99499026 -0.09997192 -0.13372452  0.02321366], Reward=-1.0\n",
            "Step 10: State=[ 0.99995316 -0.00967892  0.99881411 -0.04868639 -0.30506689  0.47501547], Reward=-1.0\n",
            "Step 11: State=[ 0.99675822 -0.08045531  0.99684629  0.07935665 -0.3849577   0.7727816 ], Reward=-1.0\n",
            "Step 12: State=[ 0.99170397 -0.12854274  0.98449473  0.17541418 -0.08663402  0.17368478], Reward=-1.0\n",
            "Step 13: State=[ 0.9920067  -0.1261852   0.98391828  0.1786192   0.10976214 -0.1408726 ], Reward=-1.0\n",
            "Step 14: State=[ 0.99497787 -0.1000951   0.98765998  0.15661343  0.14684932 -0.07459279], Reward=-1.0\n",
            "Step 15: State=[ 0.99903336 -0.0439584   0.99645135  0.0841707   0.40227718 -0.63407163], Reward=-1.0\n",
            "Step 16: State=[ 0.99862196  0.05248033  0.99659054 -0.08250628  0.53732208 -0.98986261], Reward=-1.0\n",
            "Step 17: State=[ 0.98932509  0.14572531  0.96728084 -0.25370806  0.37627495 -0.70609011], Reward=-1.0\n",
            "Step 18: State=[ 0.98098571  0.19407995  0.93894641 -0.34406344  0.10288164 -0.22044293], Reward=-1.0\n",
            "Step 19: State=[ 0.9828789   0.18425272  0.94248984 -0.3342348  -0.20038787  0.3213955 ], Reward=-1.0\n",
            "Step 20: State=[ 0.99130903  0.13155384  0.96573774 -0.25951996 -0.32036272  0.44051183], Reward=-1.0\n",
            "Step 21: State=[ 0.99930994  0.03714343  0.99434992 -0.10615195 -0.60395305  1.08114255], Reward=-1.0\n",
            "Step 22: State=[ 0.99751407 -0.07046761  0.99690235  0.07864919 -0.44514933  0.72051975], Reward=-1.0\n",
            "Step 23: State=[ 0.99133625 -0.13134854  0.98623494  0.16535007 -0.15252787  0.13046126], Reward=-1.0\n",
            "Step 24: State=[ 0.99173262 -0.12832151  0.99191719  0.1268869   0.18101674 -0.51177034], Reward=-1.0\n",
            "Step 25: State=[ 0.99799135 -0.06335029  0.99956138 -0.02961491  0.45334891 -1.01901918], Reward=-1.0\n",
            "Step 26: State=[ 0.99910255  0.04235679  0.96642836 -0.25693623  0.57462449 -1.22494389], Reward=-1.0\n",
            "Step 27: State=[ 0.99180008  0.1277991   0.90961048 -0.41546212  0.26375848 -0.42611925], Reward=-1.0\n",
            "Step 28: State=[ 0.98583552  0.16771504  0.88289857 -0.46956375  0.13066489 -0.16298302], Reward=-1.0\n",
            "Step 29: State=[ 0.98635617  0.16462533  0.89721977 -0.4415843  -0.160796    0.47237023], Reward=-1.0\n",
            "Step 30: State=[ 0.99279488  0.11982624  0.94274767 -0.33350686 -0.2797425   0.67603176], Reward=-1.0\n",
            "Step 31: State=[ 0.99891988  0.04646586  0.98636018 -0.1646013  -0.43685647  1.03092368], Reward=-1.0\n",
            "Step 32: State=[ 0.99950174 -0.03156374  0.99983351  0.01824716 -0.3217291   0.76052655], Reward=-1.0\n",
            "Step 33: State=[ 0.99487849 -0.10107818  0.9815813   0.19104488 -0.35498366  0.93744396], Reward=-1.0\n",
            "Step 34: State=[ 0.98844197 -0.1515997   0.9421641   0.33515193 -0.14064049  0.5272661 ], Reward=-1.0\n",
            "Step 35: State=[ 0.99001526 -0.14096024  0.93532951  0.35377776  0.24563486 -0.32903536], Reward=-1.0\n",
            "Step 36: State=[ 0.99745757 -0.07126289  0.96884744  0.24765829  0.43849632 -0.75647382], Reward=-1.0\n",
            "Step 37: State=[ 0.99926491  0.03833591  0.99919152  0.04020324  0.62966153 -1.29130178], Reward=-1.0\n",
            "Step 38: State=[ 0.99018857  0.13973757  0.98538056 -0.17036772  0.36193628 -0.77115349], Reward=-1.0\n",
            "Step 39: State=[ 0.9846511   0.17453429  0.96803527 -0.25081411 -0.01798048 -0.03519796], Reward=-1.0\n",
            "Step 40: State=[ 0.99114674  0.13277097  0.98295186 -0.18386312 -0.39421647  0.70384187], Reward=-1.0\n",
            "Step 41: State=[ 0.99967183  0.02561695  0.99989978  0.01415708 -0.65302066  1.23546492], Reward=-1.0\n",
            "Step 42: State=[ 0.99353331 -0.113541    0.96029293  0.2789937  -0.7032087   1.37950629], Reward=-1.0\n",
            "Step 43: State=[ 0.97123396 -0.23812729  0.85893753  0.51208038 -0.53167376  1.11105609], Reward=-1.0\n",
            "Step 44: State=[ 0.95409976 -0.29948897  0.77939717  0.62653016 -0.09342874  0.26270065], Reward=-1.0\n",
            "Step 45: State=[ 0.9586971  -0.28442903  0.78295253  0.62208146  0.2473871  -0.31667401], Reward=-1.0\n",
            "Step 46: State=[ 0.98065461 -0.19574612  0.86608317  0.49989994  0.64768021 -1.13476276], Reward=-1.0\n",
            "Step 47: State=[ 0.9991692  -0.04075428  0.97225117  0.23393945  0.87693108 -1.67166727], Reward=-1.0\n",
            "Step 48: State=[ 0.99090213  0.13458446  0.99392506 -0.11005899  0.83223085 -1.69992125], Reward=-1.0\n",
            "Step 49: State=[ 0.95929483  0.28240651  0.90414834 -0.42721866  0.63956068 -1.53134017], Reward=-1.0\n",
            "Step 0: State=[ 0.9994041  -0.03451725  0.9971361   0.07562806 -0.10860439  0.16737969], Reward=-1.0\n",
            "Step 1: State=[ 0.99934086 -0.03630201  0.9980719   0.06206833  0.09042428 -0.30072882], Reward=-1.0\n",
            "Step 2: State=[ 0.9999048  -0.01379858  0.99998698 -0.00510262  0.12798181 -0.35624056], Reward=-1.0\n",
            "Step 3: State=[ 0.99999902 -0.00139847  0.99922019 -0.03948444 -0.00732154  0.0196942 ], Reward=-1.0\n",
            "Step 4: State=[ 0.9998623  -0.01659433  0.99999692  0.00248261 -0.1400627   0.39011489], Reward=-1.0\n",
            "Step 5: State=[ 0.99853551 -0.05410024  0.99402885  0.10911756 -0.22400417  0.65359562], Reward=-1.0\n",
            "Step 6: State=[ 0.99616617 -0.08748126  0.97638825  0.2160231  -0.10092376  0.4075374 ], Reward=-1.0\n",
            "Step 7: State=[ 0.99449849 -0.10475088  0.95549286  0.29501422 -0.06663827  0.39342014], Reward=-1.0\n",
            "Step 8: State=[ 0.9950727  -0.09914799  0.94426269  0.32919292  0.12223894 -0.03768635], Reward=-1.0\n",
            "Step 9: State=[ 0.99747519 -0.07101583  0.94925866  0.31449643  0.15392152 -0.1106378 ], Reward=-1.0\n",
            "Step 10: State=[ 0.99989487 -0.01450009  0.97433094  0.22512046  0.39818267 -0.79510233], Reward=-1.0\n",
            "Step 11: State=[ 0.9977638   0.06683865  0.99869301  0.0511104   0.39376562 -0.92128154], Reward=-1.0\n",
            "Step 12: State=[ 0.99271445  0.12049075  0.99604022 -0.08890373  0.13020384 -0.4483208 ], Reward=-1.0\n",
            "Step 13: State=[ 0.9933158   0.11542841  0.9927695  -0.12003632 -0.18058554  0.13892856], Reward=-1.0\n",
            "Step 14: State=[ 0.99788734  0.06496805  0.99743341 -0.07160023 -0.31427742  0.33147352], Reward=-1.0\n",
            "Step 15: State=[ 0.99985052 -0.01728996  0.99927845  0.03798124 -0.48840678  0.73279598], Reward=-1.0\n",
            "Step 16: State=[ 0.99559143 -0.09379609  0.99070615  0.13601955 -0.25996676  0.22402354], Reward=-1.0\n",
            "Step 17: State=[ 0.99160958 -0.12926886  0.98794535  0.15480307 -0.08948432 -0.04227227], Reward=-1.0\n",
            "Step 18: State=[ 0.99000147 -0.14105703  0.98830181  0.15251074 -0.02724236  0.01776529], Reward=-1.0\n",
            "Step 19: State=[ 0.99355241 -0.11337374  0.99562081  0.09348373  0.29869591 -0.59798261], Reward=-1.0\n",
            "Step 20: State=[ 0.99959864 -0.02832959  0.99724177 -0.07422161  0.53114991 -1.0379258 ], Reward=-1.0\n",
            "Step 21: State=[ 0.99814335  0.06090851  0.97327778 -0.22963091  0.33958165 -0.49716913], Reward=-1.0\n",
            "Step 22: State=[ 0.99491575  0.10071076  0.96572559 -0.2595652   0.05132753  0.19830721], Reward=-1.0\n",
            "Step 23: State=[ 0.9955862   0.09385161  0.9823782  -0.18690392 -0.11669245  0.53383532], Reward=-1.0\n",
            "Step 24: State=[ 0.99902791  0.04408217  0.9997262  -0.02339946 -0.36686153  1.07615705], Reward=-1.0\n",
            "Step 25: State=[ 0.99953418 -0.03051925  0.98234499  0.18707839 -0.35712386  0.99090456], Reward=-1.0\n",
            "Step 26: State=[ 0.99700661 -0.07731642  0.94889997  0.31557702 -0.09977704  0.31168085], Reward=-1.0\n",
            "Step 27: State=[ 0.9955685  -0.09403911  0.93048039  0.36634169 -0.0633265   0.21735965], Reward=-1.0\n",
            "Step 28: State=[ 0.99488064 -0.10105693  0.91932403  0.39350138 -0.005156    0.07083425], Reward=-1.0\n",
            "Step 29: State=[ 0.99752684 -0.07028651  0.94415851  0.3294916   0.30661538 -0.74343426], Reward=-1.0\n",
            "Step 30: State=[ 0.99994161 -0.0108063   0.98255335  0.18598096  0.2721482  -0.70903825], Reward=-1.0\n",
            "Step 31: State=[ 0.99897241  0.04532238  0.99950385  0.03149697  0.27299625 -0.81104122], Reward=-1.0\n",
            "Step 32: State=[ 0.99579967  0.09155885  0.99252963 -0.12200381  0.17620632 -0.69328142], Reward=-1.0\n",
            "Step 33: State=[ 0.99229645  0.12388609  0.96433944 -0.26466855  0.13756229 -0.73191765], Reward=-1.0\n",
            "Step 34: State=[ 0.99160296  0.1293196   0.93240988 -0.36140256 -0.08572506 -0.27153875], Reward=-1.0\n",
            "Step 35: State=[ 0.99462704  0.10352315  0.9180887  -0.396375   -0.16951817 -0.10461648], Reward=-1.0\n",
            "Step 36: State=[ 0.99866163  0.05171984  0.92896968 -0.37015583 -0.33861066  0.37602497], Reward=-1.0\n",
            "Step 37: State=[ 0.9999211  -0.01256182  0.95549474 -0.29500815 -0.28922323  0.39799194], Reward=-1.0\n",
            "Step 38: State=[ 0.9983067  -0.05816979  0.97385633 -0.22716482 -0.15597673  0.28609337], Reward=-1.0\n",
            "Step 39: State=[ 0.99743562 -0.07156949  0.98180125 -0.18991132  0.02536133  0.08658612], Reward=-1.0\n",
            "Step 40: State=[ 0.99811561 -0.06136154  0.98700709 -0.16067668  0.07560331  0.20717636], Reward=-1.0\n",
            "Step 41: State=[ 0.99958069 -0.02895597  0.98963061 -0.14363587  0.24254766 -0.03221461], Reward=-1.0\n",
            "Step 42: State=[ 0.9999869   0.00511778  0.99476025 -0.10223525  0.09259272  0.44737078], Reward=-1.0\n",
            "Step 43: State=[ 0.99978293  0.0208349   0.99999062 -0.0043316   0.06467301  0.51865114], Reward=-1.0\n",
            "Step 44: State=[0.99900681 0.04455778 0.99793864 0.06417526 0.16983888 0.15906185], Reward=-1.0\n",
            "Step 45: State=[ 0.9982059   0.05987475  0.99186074  0.12732742 -0.0172087   0.4663324 ], Reward=-1.0\n",
            "Step 46: State=[ 0.99863118  0.05230446  0.97803914  0.20842132 -0.05478585  0.34182206], Reward=-1.0\n",
            "Step 47: State=[ 0.99921484  0.03961958  0.96659309  0.2563158  -0.06844513  0.14098069], Reward=-1.0\n",
            "Step 48: State=[ 0.9992217   0.03944608  0.97371873  0.22775391  0.06603056 -0.43064296], Reward=-1.0\n",
            "Step 49: State=[ 0.99869734  0.05102577  0.99192859  0.12679775  0.04464691 -0.57683896], Reward=-1.0\n"
          ]
        }
      ]
    }
  ]
}